{"_path":"/","_dir":"","_draft":false,"_partial":false,"_locale":"","title":"Home","description":"","hideTitle":true,"disableFancyImage":true,"body":{"type":"root","children":[{"type":"element","tag":"IndexHeader","props":{},"children":[]},{"type":"element","tag":"h2","props":{"id":"Ô∏è-about-me"},"children":[{"type":"text","value":"ü¶∏üèª‚Äç‚ôÇÔ∏è About Me"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"I am a first-year Computer Science Ph.D. candidate at "},{"type":"element","tag":"a","props":{"href":"https://en.sjtu.edu.cn/","rel":["nofollow"]},"children":[{"type":"text","value":"Shanghai Jiao Tong University"}]},{"type":"text","value":" and a member of "},{"type":"element","tag":"a","props":{"href":"https://www.mvig.org/","rel":["nofollow"]},"children":[{"type":"text","value":"Machine Intelligence and Vision Group (MVIG)"}]},{"type":"text","value":" under the supervision of "},{"type":"element","tag":"a","props":{"href":"https://www.mvig.org/","rel":["nofollow"]},"children":[{"type":"text","value":"Prof. Cewu Lu"}]},{"type":"text","value":"."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"I receive my bachelor degree from Shanghai Jiao Tong Universiy in 2021. My research interests lie in Robotics and 3D Vision. Previously, I have been working on deformable object perception and manipulation. Now I am particularly interested in tactile sensing and bimanual manipulation."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"In the past, I have interned at "},{"type":"element","tag":"a","props":{"href":"https://www.microsoft.com/en-us/research/lab/microsoft-research-asia/","rel":["nofollow"]},"children":[{"type":"text","value":"Microsoft Research Asia"}]},{"type":"text","value":" under the supervsion of "},{"type":"element","tag":"a","props":{"href":"https://ancientmooner.github.io/","rel":["nofollow"]},"children":[{"type":"text","value":"Han Hu"}]},{"type":"text","value":" and "},{"type":"element","tag":"a","props":{"href":"http://yue-cao.me/","rel":["nofollow"]},"children":[{"type":"text","value":"Yue Cao"}]},{"type":"text","value":". In my spare time, I enjoy watching movies and playing with robotsü§ñ."}]},{"type":"element","tag":"h2","props":{"id":"news"},"children":[{"type":"text","value":"üì∞ News"}]},{"type":"element","tag":"ShortNews","props":{},"children":[]},{"type":"element","tag":"p","props":{},"children":[{"type":"element","tag":"a","props":{"href":"/news/"},"children":[{"type":"text","value":"More news >>>"}]}]},{"type":"element","tag":"h2","props":{"id":"experiences"},"children":[{"type":"text","value":"üè´ Experiences"}]},{"type":"element","tag":"ExperienceRow","props":{"icon":"sjtu.png"},"children":[{"type":"element","tag":"p","props":{},"children":[{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"Shanghai Jiao Tong University"}]},{"type":"element","tag":"br","props":{},"children":[]},{"type":"text","value":"\nPh.D. Student / Master Student."},{"type":"element","tag":"br","props":{},"children":[]},{"type":"text","value":"\nResearch assistant in "},{"type":"element","tag":"a","props":{"href":"https://www.mvig.org/","rel":["nofollow"]},"children":[{"type":"text","value":"Machine Intelligence and Vision Group (MVIG)"}]},{"type":"text","value":", advised by "},{"type":"element","tag":"a","props":{"href":"https://www.mvig.org/","rel":["nofollow"]},"children":[{"type":"text","value":"Prof. Cewu Lu"}]},{"type":"element","tag":"br","props":{},"children":[]},{"type":"text","value":"\nSep. 2021 - Present"}]}]},{"type":"element","tag":"ExperienceRow","props":{"icon":"microsoft.png"},"children":[{"type":"element","tag":"p","props":{},"children":[{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"Microsoft Research Asia"}]},{"type":"element","tag":"br","props":{},"children":[]},{"type":"text","value":"\nResearch Intern, advised by "},{"type":"element","tag":"a","props":{"href":"https://ancientmooner.github.io/","rel":["nofollow"]},"children":[{"type":"text","value":"Han Hu"}]},{"type":"text","value":" and "},{"type":"element","tag":"a","props":{"href":"http://yue-cao.me/","rel":["nofollow"]},"children":[{"type":"text","value":"Yue Cao"}]},{"type":"text","value":"."},{"type":"element","tag":"br","props":{},"children":[]},{"type":"text","value":"\nJul. 2019 - Mar. 2020"}]}]},{"type":"element","tag":"ExperienceRow","props":{"icon":"sjtu.png"},"children":[{"type":"element","tag":"p","props":{},"children":[{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"Shanghai Jiao Tong University"}]},{"type":"element","tag":"br","props":{},"children":[]},{"type":"text","value":"\nBachelor of Engineering in Computer Science. "},{"type":"element","tag":"br","props":{},"children":[]},{"type":"text","value":"\nSep 2016 - Jun. 2021"}]}]},{"type":"element","tag":"h2","props":{"id":"selected-publications"},"children":[{"type":"text","value":"üìÑ Selected Publications"}]},{"type":"element","tag":"PublicationRow","props":{":artifactLinks":"{\"Proceeding\":\"https://openreview.net/pdf?id=ANJuNDFdvP\",\"arXiv\":\"https://arxiv.org/abs/2311.01267\",\"Code\":\"https://github.com/xiaoxiaoxh/UniFolding\",\"Website\":\"https://unifolding.robotflow.ai/\"}",":authors":"[\"Han Xue*\",\"Yutong Li*\",\"Wenqiang Xu\",\"Huanyu Li\",\"Dongzhe Zheng\",\"Cewu Lu (*Equal contribution)\"]",":venue":"{\"acronym\":\"CoRL\",\"year\":2023,\"name\":\"7th Annual Conference on Robot Learning.\"}","thumbnail":"unifolding.gif","title":"UniFolding: Towards Sample-efficient, Scalable, and Generalizable Robotic Garment Folding","type":"conference"},"children":[]},{"type":"element","tag":"PublicationRow","props":{":artifactLinks":"{\"Proceeding\":\"https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_ClothPose_A_Real-world_Benchmark_for_Visual_Analysis_of_Garment_Pose_ICCV_2023_paper.pdf\"}",":authors":"[\"Wenqiang Xu*\",\"Wenxin Du*\",\"Han Xue\",\"Yutong Li\",\"Ruolin Ye\",\"Yan-Feng Wang\",\"Cewu Lu (*Equal contribution)\"]",":venue":"{\"acronym\":\"ICCV\",\"year\":2023,\"name\":\"Proceedings of the IEEE/CVF International Conference on Computer Vision\"}","thumbnail":"clothpose.png","title":"ClothPose: A Real-world Benchmark for Visual Analysis of Garment Pose via An Indirect Recording Solution","type":"conference"},"children":[{"type":"element","tag":"p","props":{},"children":[{"type":"element","tag":"span","props":{"className":["text-red-600","font-bold"]},"children":[{"type":"text","value":"üî• Oral Presentation."}]}]}]},{"type":"element","tag":"PublicationRow","props":{":artifactLinks":"{\"Proceeding\":\"https://openaccess.thecvf.com/content/CVPR2023/papers/Xue_GarmentTracking_Category-Level_Garment_Pose_Tracking_CVPR_2023_paper.pdf\",\"arXiv\":\"https://arxiv.org/pdf/2303.13913.pdf\",\"Code\":\"https://github.com/xiaoxiaoxh/GarmentTracking\",\"Website\":\"https://garment-tracking.robotflow.ai/\"}",":authors":"[\"Han Xue\",\"Wenqiang Xu\",\"Jieyi Zhang\",\"Tutian Tang\",\"Yutong Li\",\"Wenxin Du\",\"Ruolin Ye\",\"Cewu Lu\"]",":venue":"{\"acronym\":\"CVPR\",\"year\":2023,\"name\":\"Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition.\"}","thumbnail":"garment-tracking.gif","title":"GarmentTracking: Category-Level Garment Pose Tracking","type":"conference"},"children":[]},{"type":"element","tag":"PublicationRow","props":{":artifactLinks":"{\"Proceeding\":\"https://openaccess.thecvf.com/content/CVPR2023/papers/Xu_Visual-Tactile_Sensing_for_In-Hand_Object_Reconstruction_CVPR_2023_paper.pdf\",\"arXiv\":\"https://arxiv.org/pdf/2303.14498.pdf\",\"Code\":\"https://github.com/jeffsonyu/VTacO\",\"Website\":\"https://sites.google.com/view/vtaco/\"}",":authors":"[\"Wenqiang Xu*\",\"Zhenjun Yu*\",\"Han Xue\",\"Ruolin Ye\",\"Siqiong Yao\",\"Cewu Lu (*Equal contribution)\"]",":venue":"{\"acronym\":\"CVPR\",\"year\":2023,\"name\":\"Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition.\"}","thumbnail":"vtaco.png","title":"Visual-Tactile Sensing for In-Hand Object Reconstruction","type":"conference"},"children":[]},{"type":"element","tag":"PublicationRow","props":{":artifactLinks":"{\"Proceeding\":\"https://www.roboticsproceedings.org/rss19/p087.pdf\",\"Code\":\"https://github.com/mvig-robotflow/pyrfuniverse\",\"Website\":\"https://sites.google.com/view/rfuniverse\"}",":authors":"[\"Haoyuan Fu*\",\"Wenqiang Xu*\",\"Ruolin Ye*\",\"Han Xue\",\"Zhenjun Yu\",\"Tutian Tang\",\"Yutong Li\",\"Wenxin Du\",\"Jieyi Zhang\",\"Cewu Lu (*Equal contribution)\"]",":venue":"{\"acronym\":\"RSS\",\"year\":2023,\"name\":\"Robotics: Science and Systems.\"}","thumbnail":"rfuniverse.png","title":"Demonstrating RFUniverse: A Multiphysics Simulation Platform for Embodied AI","type":"conference"},"children":[]},{"type":"element","tag":"PublicationRow","props":{":artifactLinks":"{\"arXiv\":\"https://arxiv.org/pdf/2105.03260\"}",":authors":"[\"Liu Liu*\",\"Han Xue*\",\"Wenqiang Xu\",\"Haoyuan Fu\",\"Cewu Lu (*Equal contribution)\"]",":venue":"{\"acronym\":\"TIP\",\"year\":2022,\"name\":\"IEEE Transactions on Image Processing.\"}","thumbnail":"articulation_real.png","title":"Toward Real-World Category-Level Articulation Pose Estimation","type":"journal"},"children":[]},{"type":"element","tag":"PublicationRow","props":{":artifactLinks":"{\"Proceeding\":\"https://www.bmvc2021-virtualconference.com/assets/papers/0544.pdf\",\"arXiv\":\"https://arxiv.org/pdf/2112.07334.pdf\",\"Code\":\"https://github.com/xiaoxiaoxh/OMAD\"}",":authors":"[\"Han Xue*\",\"Liu Liu*\",\"Wenqiang Xu\",\"Haoyuan Fu\",\"Cewu Lu (*Equal contribution)\"]",":venue":"{\"acronym\":\"BMVC\",\"year\":2021,\"name\":\"The 32nd British Machine Vision Conference.\"}","thumbnail":"omad.png","title":"OMAD: Object Model with Articulated Deformations for Pose Estimation and Retrieval","type":"conference"},"children":[]},{"type":"element","tag":"PublicationRow","props":{":artifactLinks":"{\"Proceeding\":\"https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123660222.pdf\",\"arXiv\":\"https://arxiv.org/pdf/1912.11473.pdf\",\"Code\":\"https://github.com/justimyhxu/Dense-RepPoints\"}",":authors":"[\"Ze Yang*\",\"Yinghao Xu*\",\"Han Xue*\",\"Zheng Zhang\",\"Raquel Urtasun\",\"Liwei Wang\",\"Stephen Lin\",\"Han Hu (*Equal contribution)\"]",":venue":"{\"acronym\":\"ECCV\",\"year\":2020,\"name\":\"The European Conference on Computer Vision.\"}","thumbnail":"dense_reppoints.jpg","title":"Dense RepPoints: Representing Visual Objects with Dense Point Sets","type":"conference"},"children":[]},{"type":"element","tag":"PublicationRow","props":{":artifactLinks":"{\"Proceeding\":\"http://openaccess.thecvf.com/content_cvpr_2018/papers/Chen_LiDAR-Video_Driving_Dataset_CVPR_2018_paper.pdf\",\"Code\":\"https://github.com/driving-behavior/DBNet\",\"Website\":\"http://www.dbehavior.net/\"}",":authors":"[\"Yiping Chen*\",\"Jingkang Wang*\",\"Jonathan Li\",\"Cewu Lu\",\"Zhipeng Luo\",\"Han Xue\",\"Cheng Wang (*Equal contribution)\"]",":venue":"{\"acronym\":\"CVPR\",\"year\":2018,\"name\":\"Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.\"}","thumbnail":"dbnet.jpg","title":"Lidar-video driving dataset: Learning driving policies effectively","type":"conference",":hideBottomBorder":"true"},"children":[]},{"type":"element","tag":"p","props":{},"children":[{"type":"element","tag":"a","props":{"href":"/publication/"},"children":[{"type":"text","value":"Full publication list >>>"}]}]},{"type":"element","tag":"h2","props":{"id":"awards"},"children":[{"type":"text","value":"üèÜ Awards"}]},{"type":"element","tag":"ul","props":{},"children":[{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"Outstanding Graduates in Shanghai (Top 3%) in 2021."}]},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"Rongchang Technology Innovation Scholarship (Top 10 students in SJTU) in 2020."}]},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"SenseTime Scholarship (Top 21 undergraduates in China) in 2020."}]},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"National Scholarship (Top 3 students in CS Department).\n"},{"type":"element","tag":"ul","props":{},"children":[{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"National Scholarship in 2019"}]},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"National Scholarship in 2018"}]},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"National Scholarship in 2017"}]}]}]},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"Academic Excellence Scholarship (Class A) of SJTU (Top 1% in SJTU) in 2018."}]},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"Meritorious Winner Prize of Mathematical Contest in Modeling in 2018."}]},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"1st Prize in China Undergraduate Mathematical Contest in Modeling (Shanghai Division) in 2017."}]}]},{"type":"element","tag":"h2","props":{"id":"find-me"},"children":[{"type":"text","value":"üìß Find Me"}]},{"type":"element","tag":"contact-item","props":{"icon":"email","url":"mailto:xiaoxiaoxh@sjtu.edu.cn"},"children":[{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Email"}]}]},{"type":"element","tag":"contact-item","props":{"icon":"github","url":"https://github.com/xiaoxiaoxh"},"children":[{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"GitHub"}]}]},{"type":"element","tag":"contact-item","props":{"icon":"twitter","url":"https://twitter.com/HanXue012"},"children":[{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Twitter"}]}]}],"toc":{"title":"","searchDepth":2,"depth":2,"links":[{"id":"Ô∏è-about-me","depth":2,"text":"ü¶∏üèª‚Äç‚ôÇÔ∏è About Me"},{"id":"news","depth":2,"text":"üì∞ News"},{"id":"experiences","depth":2,"text":"üè´ Experiences"},{"id":"selected-publications","depth":2,"text":"üìÑ Selected Publications"},{"id":"awards","depth":2,"text":"üèÜ Awards"},{"id":"find-me","depth":2,"text":"üìß Find Me"}]}},"_type":"markdown","_id":"content:index.md","_source":"content","_file":"index.md","_extension":"md"}