{"_path":"/publication","_dir":"","_draft":false,"_partial":false,"_locale":"","title":"Publications","description":"","body":{"type":"root","children":[{"type":"element","tag":"MarkdownHeader","props":{"title":"Publications"},"children":[]},{"type":"element","tag":"PublicationRow","props":{":artifactLinks":"{\"Website\":\"https://reactive-diffusion-policy.github.io/\",\"arXiv\":\"https://arxiv.org/abs/2503.02881\",\"Code\":\"https://github.com/xiaoxiaoxh/reactive_diffusion_policy\"}",":authors":"[\"Han Xue*\",\"Jieji Ren*\",\"Wendi Chen*\",\"Gu Zhang\",\"Yuan Fang\",\"Guoying Gu\",\"Huazhe Xuâ€ \",\"Cewu Luâ€  (â€ Equal advising)\"]",":venue":"{\"acronym\":\"RSS\",\"year\":2025,\"name\":\"Robotics: Science and Systems (RSS)\"}","thumbnail":"rdp.gif","title":"Reactive Diffusion Policy: Slow-Fast Visual-Tactile Policy Learning for Contact-Rich Manipulation","type":"conference"},"children":[{"type":"element","tag":"p","props":{},"children":[{"type":"element","tag":"span","props":{"className":["text-red-600","font-bold"]},"children":[{"type":"text","value":"ðŸ”¥ Best Paper Award "},{"type":"element","tag":"a","props":{"href":"https://sites.google.com/view/icra-2025-beyond-pick-place/home","rel":["nofollow"]},"children":[{"type":"text","value":"@ Beyond P&P Workshop in ICRA 2025"}]},{"type":"text","value":"."}]}]}]},{"type":"element","tag":"PublicationRow","props":{":artifactLinks":"{\"Website\":\"https://deform-pam.robotflow.ai/\",\"arXiv\":\"https://arxiv.org/abs/2410.11584\",\"Code\":\"https://github.com/xiaoxiaoxh/DeformPAM\"}",":authors":"[\"Wendi Chen*\",\"Han Xue*\",\"Fangyuan Zhou\",\"Yuan Fang\",\"Cewu Lu (*Equal contribution)\"]",":venue":"{\"acronym\":\"ICRA\",\"year\":2025,\"name\":\"IEEE International Conference on Robotics and Automation (ICRA)\"}","thumbnail":"deform-pam.gif","title":"DeformPAM: Data-Efficient Learning for Long-horizon Deformable Object Manipulation via Preference-based Action Alignment","type":"conference"},"children":[{"type":"element","tag":"p","props":{},"children":[{"type":"element","tag":"span","props":{"className":["text-red-600","font-bold"]},"children":[{"type":"text","value":"ðŸ”¥ Best Paper Finalist "},{"type":"element","tag":"a","props":{"href":"https://deformable-workshop.github.io/icra2025/","rel":["nofollow"]},"children":[{"type":"text","value":"@ RMDO Workshop in ICRA 2025"}]},{"type":"text","value":"."}]}]}]},{"type":"element","tag":"PublicationRow","props":{":artifactLinks":"{\"Proceeding\":\"https://openreview.net/pdf?id=ANJuNDFdvP\",\"arXiv\":\"https://arxiv.org/abs/2311.01267\",\"Code\":\"https://github.com/xiaoxiaoxh/UniFolding\",\"Website\":\"https://unifolding.robotflow.ai/\"}",":authors":"[\"Han Xue*\",\"Yutong Li*\",\"Wenqiang Xu\",\"Huanyu Li\",\"Dongzhe Zheng\",\"Cewu Lu (*Equal contribution)\"]",":venue":"{\"acronym\":\"CoRL\",\"year\":2023,\"name\":\"7th Annual Conference on Robot Learning.\"}","thumbnail":"unifolding.gif","title":"UniFolding: Towards Sample-efficient, Scalable, and Generalizable Robotic Garment Folding","type":"conference"},"children":[]},{"type":"element","tag":"PublicationRow","props":{":artifactLinks":"{\"Proceeding\":\"https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_ClothPose_A_Real-world_Benchmark_for_Visual_Analysis_of_Garment_Pose_ICCV_2023_paper.pdf\"}",":authors":"[\"Wenqiang Xu*\",\"Wenxin Du*\",\"Han Xue\",\"Yutong Li\",\"Ruolin Ye\",\"Yan-Feng Wang\",\"Cewu Lu (*Equal contribution)\"]",":venue":"{\"acronym\":\"ICCV\",\"year\":2023,\"name\":\"Proceedings of the IEEE/CVF International Conference on Computer Vision\"}","thumbnail":"clothpose.png","title":"ClothPose: A Real-world Benchmark for Visual Analysis of Garment Pose via An Indirect Recording Solution","type":"conference"},"children":[{"type":"element","tag":"p","props":{},"children":[{"type":"element","tag":"span","props":{"className":["text-red-600","font-bold"]},"children":[{"type":"text","value":"ðŸ”¥ Oral Presentation."}]}]}]},{"type":"element","tag":"PublicationRow","props":{":artifactLinks":"{\"Proceeding\":\"https://openaccess.thecvf.com/content/CVPR2023/papers/Xue_GarmentTracking_Category-Level_Garment_Pose_Tracking_CVPR_2023_paper.pdf\",\"arXiv\":\"https://arxiv.org/pdf/2303.13913.pdf\",\"Code\":\"https://github.com/xiaoxiaoxh/GarmentTracking\",\"Website\":\"https://garment-tracking.robotflow.ai/\"}",":authors":"[\"Han Xue\",\"Wenqiang Xu\",\"Jieyi Zhang\",\"Tutian Tang\",\"Yutong Li\",\"Wenxin Du\",\"Ruolin Ye\",\"Cewu Lu\"]",":venue":"{\"acronym\":\"CVPR\",\"year\":2023,\"name\":\"Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition.\"}","thumbnail":"garment-tracking.gif","title":"GarmentTracking: Category-Level Garment Pose Tracking","type":"conference"},"children":[]},{"type":"element","tag":"PublicationRow","props":{":artifactLinks":"{\"Proceeding\":\"https://openaccess.thecvf.com/content/CVPR2023/papers/Xu_Visual-Tactile_Sensing_for_In-Hand_Object_Reconstruction_CVPR_2023_paper.pdf\",\"arXiv\":\"https://arxiv.org/pdf/2303.14498.pdf\",\"Code\":\"https://github.com/jeffsonyu/VTacO\",\"Website\":\"https://sites.google.com/view/vtaco/\"}",":authors":"[\"Wenqiang Xu*\",\"Zhenjun Yu*\",\"Han Xue\",\"Ruolin Ye\",\"Siqiong Yao\",\"Cewu Lu (*Equal contribution)\"]",":venue":"{\"acronym\":\"CVPR\",\"year\":2023,\"name\":\"Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition.\"}","thumbnail":"vtaco.png","title":"Visual-Tactile Sensing for In-Hand Object Reconstruction","type":"conference"},"children":[]},{"type":"element","tag":"PublicationRow","props":{":artifactLinks":"{\"Proceeding\":\"https://www.roboticsproceedings.org/rss19/p087.pdf\",\"Code\":\"https://github.com/mvig-robotflow/pyrfuniverse\",\"Website\":\"https://sites.google.com/view/rfuniverse\"}",":authors":"[\"Haoyuan Fu*\",\"Wenqiang Xu*\",\"Ruolin Ye*\",\"Han Xue\",\"Zhenjun Yu\",\"Tutian Tang\",\"Yutong Li\",\"Wenxin Du\",\"Jieyi Zhang\",\"Cewu Lu (*Equal contribution)\"]",":venue":"{\"acronym\":\"RSS\",\"year\":2023,\"name\":\"Robotics: Science and Systems.\"}","thumbnail":"rfuniverse.png","title":"Demonstrating RFUniverse: A Multiphysics Simulation Platform for Embodied AI","type":"conference"},"children":[]},{"type":"element","tag":"PublicationRow","props":{":artifactLinks":"{\"arXiv\":\"https://arxiv.org/pdf/2105.03260\"}",":authors":"[\"Liu Liu*\",\"Han Xue*\",\"Wenqiang Xu\",\"Haoyuan Fu\",\"Cewu Lu (*Equal contribution)\"]",":venue":"{\"acronym\":\"TIP\",\"year\":2022,\"name\":\"IEEE Transactions on Image Processing.\"}","thumbnail":"articulation_real.png","title":"Toward Real-World Category-Level Articulation Pose Estimation","type":"journal"},"children":[]},{"type":"element","tag":"PublicationRow","props":{":artifactLinks":"{\"Proceeding\":\"https://www.bmvc2021-virtualconference.com/assets/papers/0544.pdf\",\"arXiv\":\"https://arxiv.org/pdf/2112.07334.pdf\",\"Code\":\"https://github.com/xiaoxiaoxh/OMAD\"}",":authors":"[\"Han Xue*\",\"Liu Liu*\",\"Wenqiang Xu\",\"Haoyuan Fu\",\"Cewu Lu (*Equal contribution)\"]",":venue":"{\"acronym\":\"BMVC\",\"year\":2021,\"name\":\"The 32nd British Machine Vision Conference.\"}","thumbnail":"omad.png","title":"OMAD: Object Model with Articulated Deformations for Pose Estimation and Retrieval","type":"conference"},"children":[]},{"type":"element","tag":"PublicationRow","props":{":artifactLinks":"{\"Proceeding\":\"https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123660222.pdf\",\"arXiv\":\"https://arxiv.org/pdf/1912.11473.pdf\",\"Code\":\"https://github.com/justimyhxu/Dense-RepPoints\"}",":authors":"[\"Ze Yang*\",\"Yinghao Xu*\",\"Han Xue*\",\"Zheng Zhang\",\"Raquel Urtasun\",\"Liwei Wang\",\"Stephen Lin\",\"Han Hu (*Equal contribution)\"]",":venue":"{\"acronym\":\"ECCV\",\"year\":2020,\"name\":\"The European Conference on Computer Vision.\"}","thumbnail":"dense_reppoints.jpg","title":"Dense RepPoints: Representing Visual Objects with Dense Point Sets","type":"conference"},"children":[]},{"type":"element","tag":"PublicationRow","props":{":artifactLinks":"{\"Proceeding\":\"http://openaccess.thecvf.com/content_cvpr_2018/papers/Chen_LiDAR-Video_Driving_Dataset_CVPR_2018_paper.pdf\",\"Code\":\"https://github.com/driving-behavior/DBNet\",\"Website\":\"http://www.dbehavior.net/\"}",":authors":"[\"Yiping Chen*\",\"Jingkang Wang*\",\"Jonathan Li\",\"Cewu Lu\",\"Zhipeng Luo\",\"Han Xue\",\"Cheng Wang (*Equal contribution)\"]",":venue":"{\"acronym\":\"CVPR\",\"year\":2018,\"name\":\"Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.\"}","thumbnail":"dbnet.jpg","title":"Lidar-video driving dataset: Learning driving policies effectively","type":"conference",":hideBottomBorder":"true"},"children":[]}],"toc":{"title":"","searchDepth":2,"depth":2,"links":[]}},"_type":"markdown","_id":"content:publication.md","_source":"content","_file":"publication.md","_extension":"md"}