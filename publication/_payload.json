[{"data":1,"prerenderedAt":181},["Reactive",2],{"content-query-FpPJaOzdgK":3},{"_path":4,"_dir":5,"_draft":6,"_partial":6,"_locale":5,"title":7,"description":5,"body":8,"_type":176,"_id":177,"_source":178,"_file":179,"_extension":180},"/publication","",false,"Publications",{"type":9,"children":10,"toc":173},"root",[11,16,26,34,41,63,91,99,116,124,131,139,148,156,164],{"type":12,"tag":13,"props":14,"children":15},"element","MarkdownHeader",{"title":7},[],{"type":12,"tag":17,"props":18,"children":25},"PublicationRow",{":artifactLinks":19,":authors":20,":venue":21,"thumbnail":22,"title":23,"type":24},"{\"Website\":\"https://implicit-rdp.github.io/\",\"arXiv\":\"https://arxiv.org/abs/2512.10946\"}","[\"Wendi Chen\",\"Han Xue\",\"Yi Wang\",\"Fangyuan Zhou\",\"Jun Lv\",\"Yang Jin\",\"Shirun Tang\",\"Chuan Wenâ€ \",\"Cewu Luâ€  (â€ equal advising)\"]","{\"acronym\":\"arXiv\",\"year\":2025,\"name\":\"arXiv\"}","ImplicitRDP.gif","ImplicitRDP: An End-to-End Visual-Force Diffusion Policy with Structural Slow-Fast Learning","conference",[],{"type":12,"tag":17,"props":27,"children":33},{":artifactLinks":28,":authors":29,":venue":30,"thumbnail":31,"title":32,"type":24},"{\"Website\":\"https://ericjin2002.github.io/SOE\",\"arXiv\":\"https://arxiv.org/abs/2509.19292\"}","[\"Yang Jin\",\"Jun Lv\",\"Han Xue\",\"Wendi Chen\",\"Chuan Wenâ€ \",\"Cewu Luâ€  (â€ equal advising)\"]","{\"acronym\":\"ICRA\",\"year\":2026,\"name\":\"IEEE International Conference on Robotics and Automation (ICRA)\"}","SOE.gif","SOE: Sample-Efficient Robot Policy Self-Improvement via On-Manifold Exploration",[],{"type":12,"tag":17,"props":35,"children":40},{":artifactLinks":36,":authors":37,":venue":30,"thumbnail":38,"title":39,"type":24},"{\"Website\":\"https://right-side-out.github.io/\",\"arXiv\":\"https://arxiv.org/abs/2509.15953\"}","[\"Chang Yu*\",\"Siyu Ma*\",\"Wenxin Du\",\"Zeshun Zong\",\"Han Xue\",\"Wendi Chen\",\"Cewu Lu\",\"Yin Yang\",\"Xuchen Han\",\"Joseph Masterjohn\",\"Alejandro Castro\",\"Chenfanfu Jiang (*Equal contribution)\"]","Right-Side-Out.gif","Right-Side-Out: Learning Zero-Shot Sim-to-Real Garment Reversal",[],{"type":12,"tag":17,"props":42,"children":48},{":artifactLinks":43,":authors":44,":venue":45,"thumbnail":46,"title":47,"type":24},"{\"Website\":\"https://reactive-diffusion-policy.github.io/\",\"arXiv\":\"https://arxiv.org/abs/2503.02881\",\"Code\":\"https://github.com/xiaoxiaoxh/reactive_diffusion_policy\"}","[\"Han Xue*\",\"Jieji Ren*\",\"Wendi Chen*\",\"Gu Zhang\",\"Yuan Fang\",\"Guoying Gu\",\"Huazhe Xuâ€ \",\"Cewu Luâ€  (â€ Equal advising)\"]","{\"acronym\":\"RSS\",\"year\":2025,\"name\":\"Robotics: Science and Systems (RSS)\"}","rdp.gif","Reactive Diffusion Policy: Slow-Fast Visual-Tactile Policy Learning for Contact-Rich Manipulation",[49],{"type":12,"tag":50,"props":51,"children":52},"p",{},[53],{"type":12,"tag":54,"props":55,"children":59},"span",{"className":56},[57,58],"text-red-600","font-bold",[60],{"type":61,"value":62},"text","ðŸ”¥ Best Student Paper Finalist.",{"type":12,"tag":17,"props":64,"children":70},{":artifactLinks":65,":authors":66,":venue":67,"thumbnail":68,"title":69,"type":24},"{\"Website\":\"https://deform-pam.robotflow.ai/\",\"arXiv\":\"https://arxiv.org/abs/2410.11584\",\"Code\":\"https://github.com/xiaoxiaoxh/DeformPAM\"}","[\"Wendi Chen*\",\"Han Xue*\",\"Fangyuan Zhou\",\"Yuan Fang\",\"Cewu Lu (*Equal contribution)\"]","{\"acronym\":\"ICRA\",\"year\":2025,\"name\":\"IEEE International Conference on Robotics and Automation (ICRA)\"}","deform-pam.gif","DeformPAM: Data-Efficient Learning for Long-horizon Deformable Object Manipulation via Preference-based Action Alignment",[71],{"type":12,"tag":50,"props":72,"children":73},{},[74],{"type":12,"tag":54,"props":75,"children":77},{"className":76},[57,58],[78,80,89],{"type":61,"value":79},"ðŸ”¥ Best Paper Finalist ",{"type":12,"tag":81,"props":82,"children":86},"a",{"href":83,"rel":84},"https://deformable-workshop.github.io/icra2025/",[85],"nofollow",[87],{"type":61,"value":88},"@ RMDO Workshop in ICRA 2025",{"type":61,"value":90},".",{"type":12,"tag":17,"props":92,"children":98},{":artifactLinks":93,":authors":94,":venue":95,"thumbnail":96,"title":97,"type":24},"{\"Proceeding\":\"https://openreview.net/pdf?id=ANJuNDFdvP\",\"arXiv\":\"https://arxiv.org/abs/2311.01267\",\"Code\":\"https://github.com/xiaoxiaoxh/UniFolding\",\"Website\":\"https://unifolding.robotflow.ai/\"}","[\"Han Xue*\",\"Yutong Li*\",\"Wenqiang Xu\",\"Huanyu Li\",\"Dongzhe Zheng\",\"Cewu Lu (*Equal contribution)\"]","{\"acronym\":\"CoRL\",\"year\":2023,\"name\":\"7th Annual Conference on Robot Learning.\"}","unifolding.gif","UniFolding: Towards Sample-efficient, Scalable, and Generalizable Robotic Garment Folding",[],{"type":12,"tag":17,"props":100,"children":106},{":artifactLinks":101,":authors":102,":venue":103,"thumbnail":104,"title":105,"type":24},"{\"Proceeding\":\"https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_ClothPose_A_Real-world_Benchmark_for_Visual_Analysis_of_Garment_Pose_ICCV_2023_paper.pdf\"}","[\"Wenqiang Xu*\",\"Wenxin Du*\",\"Han Xue\",\"Yutong Li\",\"Ruolin Ye\",\"Yan-Feng Wang\",\"Cewu Lu (*Equal contribution)\"]","{\"acronym\":\"ICCV\",\"year\":2023,\"name\":\"Proceedings of the IEEE/CVF International Conference on Computer Vision\"}","clothpose.png","ClothPose: A Real-world Benchmark for Visual Analysis of Garment Pose via An Indirect Recording Solution",[107],{"type":12,"tag":50,"props":108,"children":109},{},[110],{"type":12,"tag":54,"props":111,"children":113},{"className":112},[57,58],[114],{"type":61,"value":115},"ðŸ”¥ Oral Presentation.",{"type":12,"tag":17,"props":117,"children":123},{":artifactLinks":118,":authors":119,":venue":120,"thumbnail":121,"title":122,"type":24},"{\"Proceeding\":\"https://openaccess.thecvf.com/content/CVPR2023/papers/Xue_GarmentTracking_Category-Level_Garment_Pose_Tracking_CVPR_2023_paper.pdf\",\"arXiv\":\"https://arxiv.org/pdf/2303.13913.pdf\",\"Code\":\"https://github.com/xiaoxiaoxh/GarmentTracking\",\"Website\":\"https://garment-tracking.robotflow.ai/\"}","[\"Han Xue\",\"Wenqiang Xu\",\"Jieyi Zhang\",\"Tutian Tang\",\"Yutong Li\",\"Wenxin Du\",\"Ruolin Ye\",\"Cewu Lu\"]","{\"acronym\":\"CVPR\",\"year\":2023,\"name\":\"Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition.\"}","garment-tracking.gif","GarmentTracking: Category-Level Garment Pose Tracking",[],{"type":12,"tag":17,"props":125,"children":130},{":artifactLinks":126,":authors":127,":venue":120,"thumbnail":128,"title":129,"type":24},"{\"Proceeding\":\"https://openaccess.thecvf.com/content/CVPR2023/papers/Xu_Visual-Tactile_Sensing_for_In-Hand_Object_Reconstruction_CVPR_2023_paper.pdf\",\"arXiv\":\"https://arxiv.org/pdf/2303.14498.pdf\",\"Code\":\"https://github.com/jeffsonyu/VTacO\",\"Website\":\"https://sites.google.com/view/vtaco/\"}","[\"Wenqiang Xu*\",\"Zhenjun Yu*\",\"Han Xue\",\"Ruolin Ye\",\"Siqiong Yao\",\"Cewu Lu (*Equal contribution)\"]","vtaco.png","Visual-Tactile Sensing for In-Hand Object Reconstruction",[],{"type":12,"tag":17,"props":132,"children":138},{":artifactLinks":133,":authors":134,":venue":135,"thumbnail":136,"title":137,"type":24},"{\"Proceeding\":\"https://www.roboticsproceedings.org/rss19/p087.pdf\",\"Code\":\"https://github.com/mvig-robotflow/pyrfuniverse\",\"Website\":\"https://sites.google.com/view/rfuniverse\"}","[\"Haoyuan Fu*\",\"Wenqiang Xu*\",\"Ruolin Ye*\",\"Han Xue\",\"Zhenjun Yu\",\"Tutian Tang\",\"Yutong Li\",\"Wenxin Du\",\"Jieyi Zhang\",\"Cewu Lu (*Equal contribution)\"]","{\"acronym\":\"RSS\",\"year\":2023,\"name\":\"Robotics: Science and Systems.\"}","rfuniverse.png","Demonstrating RFUniverse: A Multiphysics Simulation Platform for Embodied AI",[],{"type":12,"tag":17,"props":140,"children":147},{":artifactLinks":141,":authors":142,":venue":143,"thumbnail":144,"title":145,"type":146},"{\"arXiv\":\"https://arxiv.org/pdf/2105.03260\"}","[\"Liu Liu*\",\"Han Xue*\",\"Wenqiang Xu\",\"Haoyuan Fu\",\"Cewu Lu (*Equal contribution)\"]","{\"acronym\":\"TIP\",\"year\":2022,\"name\":\"IEEE Transactions on Image Processing.\"}","articulation_real.png","Toward Real-World Category-Level Articulation Pose Estimation","journal",[],{"type":12,"tag":17,"props":149,"children":155},{":artifactLinks":150,":authors":151,":venue":152,"thumbnail":153,"title":154,"type":24},"{\"Proceeding\":\"https://www.bmvc2021-virtualconference.com/assets/papers/0544.pdf\",\"arXiv\":\"https://arxiv.org/pdf/2112.07334.pdf\",\"Code\":\"https://github.com/xiaoxiaoxh/OMAD\"}","[\"Han Xue*\",\"Liu Liu*\",\"Wenqiang Xu\",\"Haoyuan Fu\",\"Cewu Lu (*Equal contribution)\"]","{\"acronym\":\"BMVC\",\"year\":2021,\"name\":\"The 32nd British Machine Vision Conference.\"}","omad.png","OMAD: Object Model with Articulated Deformations for Pose Estimation and Retrieval",[],{"type":12,"tag":17,"props":157,"children":163},{":artifactLinks":158,":authors":159,":venue":160,"thumbnail":161,"title":162,"type":24},"{\"Proceeding\":\"https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123660222.pdf\",\"arXiv\":\"https://arxiv.org/pdf/1912.11473.pdf\",\"Code\":\"https://github.com/justimyhxu/Dense-RepPoints\"}","[\"Ze Yang*\",\"Yinghao Xu*\",\"Han Xue*\",\"Zheng Zhang\",\"Raquel Urtasun\",\"Liwei Wang\",\"Stephen Lin\",\"Han Hu (*Equal contribution)\"]","{\"acronym\":\"ECCV\",\"year\":2020,\"name\":\"The European Conference on Computer Vision.\"}","dense_reppoints.jpg","Dense RepPoints: Representing Visual Objects with Dense Point Sets",[],{"type":12,"tag":17,"props":165,"children":172},{":artifactLinks":166,":authors":167,":venue":168,"thumbnail":169,"title":170,"type":24,":hideBottomBorder":171},"{\"Proceeding\":\"http://openaccess.thecvf.com/content_cvpr_2018/papers/Chen_LiDAR-Video_Driving_Dataset_CVPR_2018_paper.pdf\",\"Code\":\"https://github.com/driving-behavior/DBNet\",\"Website\":\"http://www.dbehavior.net/\"}","[\"Yiping Chen*\",\"Jingkang Wang*\",\"Jonathan Li\",\"Cewu Lu\",\"Zhipeng Luo\",\"Han Xue\",\"Cheng Wang (*Equal contribution)\"]","{\"acronym\":\"CVPR\",\"year\":2018,\"name\":\"Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.\"}","dbnet.jpg","Lidar-video driving dataset: Learning driving policies effectively","true",[],{"title":5,"searchDepth":174,"depth":174,"links":175},2,[],"markdown","content:publication.md","content","publication.md","md",1770691375053]