<!DOCTYPE html>
<html >
<head><meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Home - Han Xue</title>
<link rel="icon" type="image/x-icon" href="/site-icons/favicon.ico">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.0/dist/katex.min.css">
<meta property="og:title" content="Home">
<link rel="preload" as="fetch" crossorigin="anonymous" href="/_payload.json">
<style>/*! tailwindcss v3.3.3 | MIT License | https://tailwindcss.com*/*,:after,:before{border:0 solid #e7e5e4;box-sizing:border-box}:after,:before{--tw-content:""}html{-webkit-text-size-adjust:100%;font-feature-settings:normal;font-family:ui-sans-serif,system-ui,-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Helvetica Neue,Arial,Noto Sans,sans-serif,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol,Noto Color Emoji;font-variation-settings:normal;line-height:1.5;tab-size:4}body{line-height:inherit;margin:0}hr{border-top-width:1px;color:inherit;height:0}abbr:where([title]){-webkit-text-decoration:underline dotted;text-decoration:underline dotted}h1,h2,h3,h4,h5,h6{font-size:inherit;font-weight:inherit}a{color:inherit;text-decoration:inherit}b,strong{font-weight:bolder}code,kbd,pre,samp{font-family:ui-monospace,SFMono-Regular,Menlo,Monaco,Consolas,Liberation Mono,Courier New,monospace;font-size:1em}small{font-size:80%}sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}table{border-collapse:collapse;border-color:inherit;text-indent:0}button,input,optgroup,select,textarea{font-feature-settings:inherit;color:inherit;font-family:inherit;font-size:100%;font-variation-settings:inherit;font-weight:inherit;line-height:inherit;margin:0;padding:0}button,select{text-transform:none}[type=button],[type=reset],[type=submit],button{-webkit-appearance:button;background-color:transparent;background-image:none}:-moz-focusring{outline:auto}:-moz-ui-invalid{box-shadow:none}progress{vertical-align:baseline}::-webkit-inner-spin-button,::-webkit-outer-spin-button{height:auto}[type=search]{-webkit-appearance:textfield;outline-offset:-2px}::-webkit-search-decoration{-webkit-appearance:none}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}summary{display:list-item}blockquote,dd,dl,figure,h1,h2,h3,h4,h5,h6,hr,p,pre{margin:0}fieldset{margin:0}fieldset,legend{padding:0}menu,ol,ul{list-style:none;margin:0;padding:0}dialog{padding:0}textarea{resize:vertical}input::placeholder,textarea::placeholder{color:#a8a29e;opacity:1}[role=button],button{cursor:pointer}:disabled{cursor:default}audio,canvas,embed,iframe,img,object,svg,video{display:block;vertical-align:middle}img,video{height:auto;max-width:100%}[hidden]{display:none}*,:after,:before{--tw-border-spacing-x:0;--tw-border-spacing-y:0;--tw-translate-x:0;--tw-translate-y:0;--tw-rotate:0;--tw-skew-x:0;--tw-skew-y:0;--tw-scale-x:1;--tw-scale-y:1;--tw-pan-x: ;--tw-pan-y: ;--tw-pinch-zoom: ;--tw-scroll-snap-strictness:proximity;--tw-gradient-from-position: ;--tw-gradient-via-position: ;--tw-gradient-to-position: ;--tw-ordinal: ;--tw-slashed-zero: ;--tw-numeric-figure: ;--tw-numeric-spacing: ;--tw-numeric-fraction: ;--tw-ring-inset: ;--tw-ring-offset-width:0px;--tw-ring-offset-color:#fff;--tw-ring-color:rgba(59,130,246,.5);--tw-ring-offset-shadow:0 0 #0000;--tw-ring-shadow:0 0 #0000;--tw-shadow:0 0 #0000;--tw-shadow-colored:0 0 #0000;--tw-blur: ;--tw-brightness: ;--tw-contrast: ;--tw-grayscale: ;--tw-hue-rotate: ;--tw-invert: ;--tw-saturate: ;--tw-sepia: ;--tw-drop-shadow: ;--tw-backdrop-blur: ;--tw-backdrop-brightness: ;--tw-backdrop-contrast: ;--tw-backdrop-grayscale: ;--tw-backdrop-hue-rotate: ;--tw-backdrop-invert: ;--tw-backdrop-opacity: ;--tw-backdrop-saturate: ;--tw-backdrop-sepia: }::backdrop{--tw-border-spacing-x:0;--tw-border-spacing-y:0;--tw-translate-x:0;--tw-translate-y:0;--tw-rotate:0;--tw-skew-x:0;--tw-skew-y:0;--tw-scale-x:1;--tw-scale-y:1;--tw-pan-x: ;--tw-pan-y: ;--tw-pinch-zoom: ;--tw-scroll-snap-strictness:proximity;--tw-gradient-from-position: ;--tw-gradient-via-position: ;--tw-gradient-to-position: ;--tw-ordinal: ;--tw-slashed-zero: ;--tw-numeric-figure: ;--tw-numeric-spacing: ;--tw-numeric-fraction: ;--tw-ring-inset: ;--tw-ring-offset-width:0px;--tw-ring-offset-color:#fff;--tw-ring-color:rgba(59,130,246,.5);--tw-ring-offset-shadow:0 0 #0000;--tw-ring-shadow:0 0 #0000;--tw-shadow:0 0 #0000;--tw-shadow-colored:0 0 #0000;--tw-blur: ;--tw-brightness: ;--tw-contrast: ;--tw-grayscale: ;--tw-hue-rotate: ;--tw-invert: ;--tw-saturate: ;--tw-sepia: ;--tw-drop-shadow: ;--tw-backdrop-blur: ;--tw-backdrop-brightness: ;--tw-backdrop-contrast: ;--tw-backdrop-grayscale: ;--tw-backdrop-hue-rotate: ;--tw-backdrop-invert: ;--tw-backdrop-opacity: ;--tw-backdrop-saturate: ;--tw-backdrop-sepia: }.container{width:100%}@media (min-width:640px){.container{max-width:640px}}@media (min-width:768px){.container{max-width:768px}}@media (min-width:1024px){.container{max-width:1024px}}@media (min-width:1280px){.container{max-width:1280px}}@media (min-width:1536px){.container{max-width:1536px}}.prose{color:var(--tw-prose-body);max-width:65ch}.prose :where(p):not(:where([class~=not-prose],[class~=not-prose] *)){margin-bottom:1.25em;margin-top:1.25em}.prose :where([class~=lead]):not(:where([class~=not-prose],[class~=not-prose] *)){color:var(--tw-prose-lead);font-size:1.25em;line-height:1.6;margin-bottom:1.2em;margin-top:1.2em}.prose :where(a):not(:where([class~=not-prose],[class~=not-prose] *)){color:var(--tw-prose-links);font-weight:500;text-decoration:underline}.prose :where(strong):not(:where([class~=not-prose],[class~=not-prose] *)){color:var(--tw-prose-bold);font-weight:600}.prose :where(a strong):not(:where([class~=not-prose],[class~=not-prose] *)){color:inherit}.prose :where(blockquote strong):not(:where([class~=not-prose],[class~=not-prose] *)){color:inherit}.prose :where(thead th strong):not(:where([class~=not-prose],[class~=not-prose] *)){color:inherit}.prose :where(ol):not(:where([class~=not-prose],[class~=not-prose] *)){list-style-type:decimal;margin-bottom:1.25em;margin-top:1.25em;padding-left:1.625em}.prose :where(ol[type=A]):not(:where([class~=not-prose],[class~=not-prose] *)){list-style-type:upper-alpha}.prose :where(ol[type=a]):not(:where([class~=not-prose],[class~=not-prose] *)){list-style-type:lower-alpha}.prose :where(ol[type=A s]):not(:where([class~=not-prose],[class~=not-prose] *)){list-style-type:upper-alpha}.prose :where(ol[type=a s]):not(:where([class~=not-prose],[class~=not-prose] *)){list-style-type:lower-alpha}.prose :where(ol[type=I]):not(:where([class~=not-prose],[class~=not-prose] *)){list-style-type:upper-roman}.prose :where(ol[type=i]):not(:where([class~=not-prose],[class~=not-prose] *)){list-style-type:lower-roman}.prose :where(ol[type=I s]):not(:where([class~=not-prose],[class~=not-prose] *)){list-style-type:upper-roman}.prose :where(ol[type=i s]):not(:where([class~=not-prose],[class~=not-prose] *)){list-style-type:lower-roman}.prose :where(ol[type="1"]):not(:where([class~=not-prose],[class~=not-prose] *)){list-style-type:decimal}.prose :where(ul):not(:where([class~=not-prose],[class~=not-prose] *)){list-style-type:disc;margin-bottom:1.25em;margin-top:1.25em;padding-left:1.625em}.prose :where(ol>li):not(:where([class~=not-prose],[class~=not-prose] *))::marker{color:var(--tw-prose-counters);font-weight:400}.prose :where(ul>li):not(:where([class~=not-prose],[class~=not-prose] *))::marker{color:var(--tw-prose-bullets)}.prose :where(dt):not(:where([class~=not-prose],[class~=not-prose] *)){color:var(--tw-prose-headings);font-weight:600;margin-top:1.25em}.prose :where(hr):not(:where([class~=not-prose],[class~=not-prose] *)){border-color:var(--tw-prose-hr);border-top-width:1px;margin-bottom:3em;margin-top:3em}.prose :where(blockquote):not(:where([class~=not-prose],[class~=not-prose] *)){border-left-color:var(--tw-prose-quote-borders);border-left-width:.25rem;color:var(--tw-prose-quotes);font-style:italic;font-weight:500;margin-bottom:1.6em;margin-top:1.6em;padding-left:1em;quotes:"\201C""\201D""\2018""\2019"}.prose :where(blockquote p:first-of-type):not(:where([class~=not-prose],[class~=not-prose] *)):before{content:open-quote}.prose :where(blockquote p:last-of-type):not(:where([class~=not-prose],[class~=not-prose] *)):after{content:close-quote}.prose :where(h1):not(:where([class~=not-prose],[class~=not-prose] *)){color:var(--tw-prose-headings);font-size:2.25em;font-weight:800;line-height:1.1111111;margin-bottom:.8888889em;margin-top:0}.prose :where(h1 strong):not(:where([class~=not-prose],[class~=not-prose] *)){color:inherit;font-weight:900}.prose :where(h2):not(:where([class~=not-prose],[class~=not-prose] *)){color:var(--tw-prose-headings);font-size:1.5em;font-weight:700;line-height:1.3333333;margin-bottom:1em;margin-top:2em}.prose :where(h2 strong):not(:where([class~=not-prose],[class~=not-prose] *)){color:inherit;font-weight:800}.prose :where(h3):not(:where([class~=not-prose],[class~=not-prose] *)){color:var(--tw-prose-headings);font-size:1.25em;font-weight:600;line-height:1.6;margin-bottom:.6em;margin-top:1.6em}.prose :where(h3 strong):not(:where([class~=not-prose],[class~=not-prose] *)){color:inherit;font-weight:700}.prose :where(h4):not(:where([class~=not-prose],[class~=not-prose] *)){color:var(--tw-prose-headings);font-weight:600;line-height:1.5;margin-bottom:.5em;margin-top:1.5em}.prose :where(h4 strong):not(:where([class~=not-prose],[class~=not-prose] *)){color:inherit;font-weight:700}.prose :where(img):not(:where([class~=not-prose],[class~=not-prose] *)){margin-bottom:2em;margin-top:2em}.prose :where(picture):not(:where([class~=not-prose],[class~=not-prose] *)){display:block;margin-bottom:2em;margin-top:2em}.prose :where(kbd):not(:where([class~=not-prose],[class~=not-prose] *)){border-radius:.3125rem;box-shadow:0 0 0 1px rgb(var(--tw-prose-kbd-shadows)/10%),0 3px 0 rgb(var(--tw-prose-kbd-shadows)/10%);color:var(--tw-prose-kbd);font-family:inherit;font-size:.875em;font-weight:500;padding:.1875em .375em}.prose :where(code):not(:where([class~=not-prose],[class~=not-prose] *)){color:var(--tw-prose-code);font-size:.875em;font-weight:600}.prose :where(code):not(:where([class~=not-prose],[class~=not-prose] *)):before{content:"`"}.prose :where(code):not(:where([class~=not-prose],[class~=not-prose] *)):after{content:"`"}.prose :where(a code):not(:where([class~=not-prose],[class~=not-prose] *)){color:inherit}.prose :where(h1 code):not(:where([class~=not-prose],[class~=not-prose] *)){color:inherit}.prose :where(h2 code):not(:where([class~=not-prose],[class~=not-prose] *)){color:inherit;font-size:.875em}.prose :where(h3 code):not(:where([class~=not-prose],[class~=not-prose] *)){color:inherit;font-size:.9em}.prose :where(h4 code):not(:where([class~=not-prose],[class~=not-prose] *)){color:inherit}.prose :where(blockquote code):not(:where([class~=not-prose],[class~=not-prose] *)){color:inherit}.prose :where(thead th code):not(:where([class~=not-prose],[class~=not-prose] *)){color:inherit}.prose :where(pre):not(:where([class~=not-prose],[class~=not-prose] *)){background-color:var(--tw-prose-pre-bg);border-radius:.375rem;color:var(--tw-prose-pre-code);font-size:.875em;font-weight:400;line-height:1.7142857;margin-bottom:1.7142857em;margin-top:1.7142857em;overflow-x:auto;padding:.8571429em 1.1428571em}.prose :where(pre code):not(:where([class~=not-prose],[class~=not-prose] *)){background-color:transparent;border-radius:0;border-width:0;color:inherit;font-family:inherit;font-size:inherit;font-weight:inherit;line-height:inherit;padding:0}.prose :where(pre code):not(:where([class~=not-prose],[class~=not-prose] *)):before{content:none}.prose :where(pre code):not(:where([class~=not-prose],[class~=not-prose] *)):after{content:none}.prose :where(table):not(:where([class~=not-prose],[class~=not-prose] *)){font-size:.875em;line-height:1.7142857;margin-bottom:2em;margin-top:2em;table-layout:auto;text-align:left;width:100%}.prose :where(thead):not(:where([class~=not-prose],[class~=not-prose] *)){border-bottom-color:var(--tw-prose-th-borders);border-bottom-width:1px}.prose :where(thead th):not(:where([class~=not-prose],[class~=not-prose] *)){color:var(--tw-prose-headings);font-weight:600;padding-bottom:.5714286em;padding-left:.5714286em;padding-right:.5714286em;vertical-align:bottom}.prose :where(tbody tr):not(:where([class~=not-prose],[class~=not-prose] *)){border-bottom-color:var(--tw-prose-td-borders);border-bottom-width:1px}.prose :where(tbody tr:last-child):not(:where([class~=not-prose],[class~=not-prose] *)){border-bottom-width:0}.prose :where(tbody td):not(:where([class~=not-prose],[class~=not-prose] *)){vertical-align:baseline}.prose :where(tfoot):not(:where([class~=not-prose],[class~=not-prose] *)){border-top-color:var(--tw-prose-th-borders);border-top-width:1px}.prose :where(tfoot td):not(:where([class~=not-prose],[class~=not-prose] *)){vertical-align:top}.prose :where(figure>*):not(:where([class~=not-prose],[class~=not-prose] *)){margin-bottom:0;margin-top:0}.prose :where(figcaption):not(:where([class~=not-prose],[class~=not-prose] *)){color:var(--tw-prose-captions);font-size:.875em;line-height:1.4285714;margin-top:.8571429em}.prose{--tw-prose-body:#374151;--tw-prose-headings:#111827;--tw-prose-lead:#4b5563;--tw-prose-links:#111827;--tw-prose-bold:#111827;--tw-prose-counters:#6b7280;--tw-prose-bullets:#d1d5db;--tw-prose-hr:#e5e7eb;--tw-prose-quotes:#111827;--tw-prose-quote-borders:#e5e7eb;--tw-prose-captions:#6b7280;--tw-prose-kbd:#111827;--tw-prose-kbd-shadows:17 24 39;--tw-prose-code:#111827;--tw-prose-pre-code:#e5e7eb;--tw-prose-pre-bg:#1f2937;--tw-prose-th-borders:#d1d5db;--tw-prose-td-borders:#e5e7eb;--tw-prose-invert-body:#d1d5db;--tw-prose-invert-headings:#fff;--tw-prose-invert-lead:#9ca3af;--tw-prose-invert-links:#fff;--tw-prose-invert-bold:#fff;--tw-prose-invert-counters:#9ca3af;--tw-prose-invert-bullets:#4b5563;--tw-prose-invert-hr:#374151;--tw-prose-invert-quotes:#f3f4f6;--tw-prose-invert-quote-borders:#374151;--tw-prose-invert-captions:#9ca3af;--tw-prose-invert-kbd:#fff;--tw-prose-invert-kbd-shadows:255 255 255;--tw-prose-invert-code:#fff;--tw-prose-invert-pre-code:#d1d5db;--tw-prose-invert-pre-bg:rgba(0,0,0,.5);--tw-prose-invert-th-borders:#4b5563;--tw-prose-invert-td-borders:#374151;font-size:1rem;line-height:1.75}.prose :where(picture>img):not(:where([class~=not-prose],[class~=not-prose] *)){margin-bottom:0;margin-top:0}.prose :where(video):not(:where([class~=not-prose],[class~=not-prose] *)){margin-bottom:2em;margin-top:2em}.prose :where(li):not(:where([class~=not-prose],[class~=not-prose] *)){margin-bottom:.5em;margin-top:.5em}.prose :where(ol>li):not(:where([class~=not-prose],[class~=not-prose] *)){padding-left:.375em}.prose :where(ul>li):not(:where([class~=not-prose],[class~=not-prose] *)){padding-left:.375em}.prose :where(.prose>ul>li p):not(:where([class~=not-prose],[class~=not-prose] *)){margin-bottom:.75em;margin-top:.75em}.prose :where(.prose>ul>li>:first-child):not(:where([class~=not-prose],[class~=not-prose] *)){margin-top:1.25em}.prose :where(.prose>ul>li>:last-child):not(:where([class~=not-prose],[class~=not-prose] *)){margin-bottom:1.25em}.prose :where(.prose>ol>li>:first-child):not(:where([class~=not-prose],[class~=not-prose] *)){margin-top:1.25em}.prose :where(.prose>ol>li>:last-child):not(:where([class~=not-prose],[class~=not-prose] *)){margin-bottom:1.25em}.prose :where(ul ul,ul ol,ol ul,ol ol):not(:where([class~=not-prose],[class~=not-prose] *)){margin-bottom:.75em;margin-top:.75em}.prose :where(dl):not(:where([class~=not-prose],[class~=not-prose] *)){margin-bottom:1.25em;margin-top:1.25em}.prose :where(dd):not(:where([class~=not-prose],[class~=not-prose] *)){margin-top:.5em;padding-left:1.625em}.prose :where(hr+*):not(:where([class~=not-prose],[class~=not-prose] *)){margin-top:0}.prose :where(h2+*):not(:where([class~=not-prose],[class~=not-prose] *)){margin-top:0}.prose :where(h3+*):not(:where([class~=not-prose],[class~=not-prose] *)){margin-top:0}.prose :where(h4+*):not(:where([class~=not-prose],[class~=not-prose] *)){margin-top:0}.prose :where(thead th:first-child):not(:where([class~=not-prose],[class~=not-prose] *)){padding-left:0}.prose :where(thead th:last-child):not(:where([class~=not-prose],[class~=not-prose] *)){padding-right:0}.prose :where(tbody td,tfoot td):not(:where([class~=not-prose],[class~=not-prose] *)){padding:.5714286em}.prose :where(tbody td:first-child,tfoot td:first-child):not(:where([class~=not-prose],[class~=not-prose] *)){padding-left:0}.prose :where(tbody td:last-child,tfoot td:last-child):not(:where([class~=not-prose],[class~=not-prose] *)){padding-right:0}.prose :where(figure):not(:where([class~=not-prose],[class~=not-prose] *)){margin-bottom:2em;margin-top:2em}.prose :where(.prose>:first-child):not(:where([class~=not-prose],[class~=not-prose] *)){margin-top:0}.prose :where(.prose>:last-child):not(:where([class~=not-prose],[class~=not-prose] *)){margin-bottom:0}.fixed{position:fixed}.absolute{position:absolute}.relative{position:relative}.bottom-16{bottom:4rem}.left-0{left:0}.left-\[2rem\]{left:2rem}.top-0{top:0}.top-\[-2\.5rem\]{top:-2.5rem}.isolate{isolation:isolate}.z-10{z-index:10}.z-20{z-index:20}.z-30{z-index:30}.z-\[-1\]{z-index:-1}.z-\[-2\]{z-index:-2}.m-0{margin:0}.mx-auto{margin-left:auto;margin-right:auto}.my-0{margin-bottom:0;margin-top:0}.my-12{margin-bottom:3rem;margin-top:3rem}.my-4{margin-bottom:1rem;margin-top:1rem}.my-5{margin-bottom:1.25rem;margin-top:1.25rem}.my-6{margin-bottom:1.5rem;margin-top:1.5rem}.mb-0{margin-bottom:0}.mb-10{margin-bottom:2.5rem}.mb-16{margin-bottom:4rem}.mb-4{margin-bottom:1rem}.mb-6{margin-bottom:1.5rem}.mb-8{margin-bottom:2rem}.ml-\[-20\%\]{margin-left:-20%}.mr-1{margin-right:.25rem}.mr-2{margin-right:.5rem}.mr-3{margin-right:.75rem}.mr-4{margin-right:1rem}.mt-0{margin-top:0}.mt-1{margin-top:.25rem}.mt-12{margin-top:3rem}.mt-2{margin-top:.5rem}.mt-4{margin-top:1rem}.mt-8{margin-top:2rem}.mt-\[3\.4rem\]{margin-top:3.4rem}.block{display:block}.inline{display:inline}.flex{display:flex}.hidden{display:none}.h-fit{height:-moz-fit-content;height:fit-content}.h-full{height:100%}.h-screen{height:100vh}.min-h-\[100vh\]{min-height:100vh}.w-1\/4{width:25%}.w-10{width:2.5rem}.w-2\/5{width:40%}.w-20{width:5rem}.w-24{width:6rem}.w-3\/4{width:75%}.w-6{width:1.5rem}.w-\[140\%\]{width:140%}.w-\[55\%\]{width:55%}.w-\[75\%\]{width:75%}.w-full{width:100%}.max-w-4xl{max-width:56rem}.max-w-5xl{max-width:64rem}.max-w-6xl{max-width:72rem}.max-w-none{max-width:none}.max-w-prose{max-width:65ch}.flex-grow-0{flex-grow:0}.translate-y-\[-100vh\]{--tw-translate-y:-100vh;transform:translate(var(--tw-translate-x),-100vh) rotate(var(--tw-rotate)) skewX(var(--tw-skew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--tw-scale-y));transform:translate(var(--tw-translate-x),var(--tw-translate-y)) rotate(var(--tw-rotate)) skewX(var(--tw-skew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--tw-scale-y))}.flex-row{flex-direction:row}.flex-col{flex-direction:column}.flex-wrap{flex-wrap:wrap}.items-start{align-items:flex-start}.items-center{align-items:center}.justify-start{justify-content:flex-start}.justify-end{justify-content:flex-end}.justify-center{justify-content:center}.justify-between{justify-content:space-between}.overflow-hidden{overflow:hidden}.rounded-md{border-radius:.375rem}.rounded-sm{border-radius:.125rem}.border{border-width:1px}.border-b-2{border-bottom-width:2px}.border-b-4{border-bottom-width:4px}.border-t-2{border-top-width:2px}.border-gray-200{--tw-border-opacity:1;border-color:#e7e5e4;border-color:rgb(231 229 228/var(--tw-border-opacity))}.border-b-gray-300{--tw-border-opacity:1;border-bottom-color:#d6d3d1;border-bottom-color:rgb(214 211 209/var(--tw-border-opacity))}.border-b-gray-400{--tw-border-opacity:1;border-bottom-color:#a8a29e;border-bottom-color:rgb(168 162 158/var(--tw-border-opacity))}.border-t-black{--tw-border-opacity:1;border-top-color:#000;border-top-color:rgb(0 0 0/var(--tw-border-opacity))}.bg-\[\#FAFAF9\]{--tw-bg-opacity:1;background-color:#fafaf9;background-color:rgb(250 250 249/var(--tw-bg-opacity))}.bg-black{--tw-bg-opacity:1;background-color:#000;background-color:rgb(0 0 0/var(--tw-bg-opacity))}.bg-gray-100{--tw-bg-opacity:1;background-color:#f5f5f4;background-color:rgb(245 245 244/var(--tw-bg-opacity))}.bg-gray-200{--tw-bg-opacity:1;background-color:#e7e5e4;background-color:rgb(231 229 228/var(--tw-bg-opacity))}.bg-gray-700{--tw-bg-opacity:1;background-color:#44403c;background-color:rgb(68 64 60/var(--tw-bg-opacity))}.bg-gray-900{--tw-bg-opacity:1;background-color:#1c1917;background-color:rgb(28 25 23/var(--tw-bg-opacity))}.bg-neutral-100{--tw-bg-opacity:1;background-color:#f5f5f5;background-color:rgb(245 245 245/var(--tw-bg-opacity))}.bg-neutral-200{--tw-bg-opacity:1;background-color:#e5e5e5;background-color:rgb(229 229 229/var(--tw-bg-opacity))}.bg-transparent{background-color:transparent}.p-0{padding:0}.p-12{padding:3rem}.p-4{padding:1rem}.p-5{padding:1.25rem}.p-8{padding:2rem}.px-0{padding-left:0;padding-right:0}.px-2{padding-left:.5rem;padding-right:.5rem}.px-4{padding-left:1rem;padding-right:1rem}.py-0{padding-bottom:0;padding-top:0}.py-2{padding-bottom:.5rem;padding-top:.5rem}.py-3{padding-bottom:.75rem;padding-top:.75rem}.py-4{padding-bottom:1rem;padding-top:1rem}.py-8{padding-bottom:2rem;padding-top:2rem}.py-\[0\.2em\]{padding-bottom:.2em;padding-top:.2em}.pb-16{padding-bottom:4rem}.pb-8{padding-bottom:2rem}.pl-10{padding-left:2.5rem}.pl-3{padding-left:.75rem}.pr-3{padding-right:.75rem}.pt-24{padding-top:6rem}.text-center{text-align:center}.text-justify{text-align:justify}.font-serif{font-family:Noto Serif,Times,Times New Roman}.text-2xl{font-size:1.5rem;line-height:2rem}.text-4xl{font-size:2.25rem;line-height:2.5rem}.text-6xl{font-size:3.75rem;line-height:1}.text-lg{font-size:1.125rem;line-height:1.75rem}.text-sm{font-size:.875rem;line-height:1.25rem}.text-xl{font-size:1.25rem;line-height:1.75rem}.text-xs{font-size:.75rem;line-height:1rem}.font-bold{font-weight:700}.font-medium{font-weight:500}.font-normal{font-weight:400}.uppercase{text-transform:uppercase}.italic{font-style:italic}.text-black{--tw-text-opacity:1;color:#000;color:rgb(0 0 0/var(--tw-text-opacity))}.text-gray-400{--tw-text-opacity:1;color:#a8a29e;color:rgb(168 162 158/var(--tw-text-opacity))}.text-gray-500{--tw-text-opacity:1;color:#78716c;color:rgb(120 113 108/var(--tw-text-opacity))}.text-red-600{--tw-text-opacity:1;color:#dc2626;color:rgb(220 38 38/var(--tw-text-opacity))}.text-white{--tw-text-opacity:1;color:#fff;color:rgb(255 255 255/var(--tw-text-opacity))}.underline{text-decoration-line:underline}.no-underline{text-decoration-line:none}.decoration-transparent{text-decoration-color:transparent}.opacity-0{opacity:0}.opacity-100{opacity:1}.opacity-30{opacity:.3}.opacity-40{opacity:.4}.opacity-50{opacity:.5}.opacity-60{opacity:.6}.opacity-70{opacity:.7}.opacity-75{opacity:.75}.shadow-lg{--tw-shadow:0 10px 15px -3px rgba(0,0,0,.1),0 4px 6px -4px rgba(0,0,0,.1);--tw-shadow-colored:0 10px 15px -3px var(--tw-shadow-color),0 4px 6px -4px var(--tw-shadow-color);box-shadow:0 0 #0000,0 0 #0000,0 10px 15px -3px rgba(0,0,0,.1),0 4px 6px -4px rgba(0,0,0,.1);box-shadow:var(--tw-ring-offset-shadow,0 0 #0000),var(--tw-ring-shadow,0 0 #0000),var(--tw-shadow)}.shadow-md{--tw-shadow:0 4px 6px -1px rgba(0,0,0,.1),0 2px 4px -2px rgba(0,0,0,.1);--tw-shadow-colored:0 4px 6px -1px var(--tw-shadow-color),0 2px 4px -2px var(--tw-shadow-color);box-shadow:0 0 #0000,0 0 #0000,0 4px 6px -1px rgba(0,0,0,.1),0 2px 4px -2px rgba(0,0,0,.1);box-shadow:var(--tw-ring-offset-shadow,0 0 #0000),var(--tw-ring-shadow,0 0 #0000),var(--tw-shadow)}.filter{filter:var(--tw-blur) var(--tw-brightness) var(--tw-contrast) var(--tw-grayscale) var(--tw-hue-rotate) var(--tw-invert) var(--tw-saturate) var(--tw-sepia) var(--tw-drop-shadow)}.transition{transition-duration:.15s;transition-property:color,background-color,border-color,text-decoration-color,fill,stroke,opacity,box-shadow,transform,filter,-webkit-backdrop-filter;transition-property:color,background-color,border-color,text-decoration-color,fill,stroke,opacity,box-shadow,transform,filter,backdrop-filter;transition-property:color,background-color,border-color,text-decoration-color,fill,stroke,opacity,box-shadow,transform,filter,backdrop-filter,-webkit-backdrop-filter;transition-timing-function:cubic-bezier(.4,0,.2,1)}.transition-\[opacity\2c transform\]{transition-duration:.15s;transition-property:opacity,transform;transition-timing-function:cubic-bezier(.4,0,.2,1)}.transition-colors{transition-duration:.15s;transition-property:color,background-color,border-color,text-decoration-color,fill,stroke;transition-timing-function:cubic-bezier(.4,0,.2,1)}.transition-opacity{transition-duration:.15s;transition-property:opacity;transition-timing-function:cubic-bezier(.4,0,.2,1)}.transition-transform{transition-duration:.15s;transition-property:transform;transition-timing-function:cubic-bezier(.4,0,.2,1)}.duration-0{transition-duration:0s}.duration-500{transition-duration:.5s}:is(.dark .dark\:prose-invert){--tw-prose-body:var(--tw-prose-invert-body);--tw-prose-headings:var(--tw-prose-invert-headings);--tw-prose-lead:var(--tw-prose-invert-lead);--tw-prose-links:var(--tw-prose-invert-links);--tw-prose-bold:var(--tw-prose-invert-bold);--tw-prose-counters:var(--tw-prose-invert-counters);--tw-prose-bullets:var(--tw-prose-invert-bullets);--tw-prose-hr:var(--tw-prose-invert-hr);--tw-prose-quotes:var(--tw-prose-invert-quotes);--tw-prose-quote-borders:var(--tw-prose-invert-quote-borders);--tw-prose-captions:var(--tw-prose-invert-captions);--tw-prose-kbd:var(--tw-prose-invert-kbd);--tw-prose-kbd-shadows:var(--tw-prose-invert-kbd-shadows);--tw-prose-code:var(--tw-prose-invert-code);--tw-prose-pre-code:var(--tw-prose-invert-pre-code);--tw-prose-pre-bg:var(--tw-prose-invert-pre-bg);--tw-prose-th-borders:var(--tw-prose-invert-th-borders);--tw-prose-td-borders:var(--tw-prose-invert-td-borders)}.hover\:border-b-2:hover{border-bottom-width:2px}.hover\:bg-gray-50:hover{--tw-bg-opacity:1;background-color:#fafaf9;background-color:rgb(250 250 249/var(--tw-bg-opacity))}.hover\:bg-gray-500:hover{--tw-bg-opacity:1;background-color:#78716c;background-color:rgb(120 113 108/var(--tw-bg-opacity))}.hover\:text-black:hover{--tw-text-opacity:1;color:#000;color:rgb(0 0 0/var(--tw-text-opacity))}.hover\:opacity-100:hover{opacity:1}.hover\:shadow-lg:hover{--tw-shadow:0 10px 15px -3px rgba(0,0,0,.1),0 4px 6px -4px rgba(0,0,0,.1);--tw-shadow-colored:0 10px 15px -3px var(--tw-shadow-color),0 4px 6px -4px var(--tw-shadow-color);box-shadow:0 0 #0000,0 0 #0000,0 10px 15px -3px rgba(0,0,0,.1),0 4px 6px -4px rgba(0,0,0,.1);box-shadow:var(--tw-ring-offset-shadow,0 0 #0000),var(--tw-ring-shadow,0 0 #0000),var(--tw-shadow)}:is(.dark .dark\:border-gray-600){--tw-border-opacity:1;border-color:#57534e;border-color:rgb(87 83 78/var(--tw-border-opacity))}:is(.dark .dark\:bg-gray-800){--tw-bg-opacity:1;background-color:#292524;background-color:rgb(41 37 36/var(--tw-bg-opacity))}:is(.dark .dark\:bg-neutral-600){--tw-bg-opacity:1;background-color:#525252;background-color:rgb(82 82 82/var(--tw-bg-opacity))}:is(.dark .dark\:bg-neutral-700){--tw-bg-opacity:1;background-color:#404040;background-color:rgb(64 64 64/var(--tw-bg-opacity))}:is(.dark .dark\:bg-neutral-800){--tw-bg-opacity:1;background-color:#262626;background-color:rgb(38 38 38/var(--tw-bg-opacity))}:is(.dark .dark\:bg-transparent){background-color:transparent}:is(.dark .dark\:text-gray-200){--tw-text-opacity:1;color:#e7e5e4;color:rgb(231 229 228/var(--tw-text-opacity))}:is(.dark .dark\:text-gray-400){--tw-text-opacity:1;color:#a8a29e;color:rgb(168 162 158/var(--tw-text-opacity))}:is(.dark .dark\:text-gray-500){--tw-text-opacity:1;color:#78716c;color:rgb(120 113 108/var(--tw-text-opacity))}:is(.dark .dark\:text-white){--tw-text-opacity:1;color:#fff;color:rgb(255 255 255/var(--tw-text-opacity))}:is(.dark .dark\:invert){--tw-invert:invert(100%);filter:var(--tw-blur) var(--tw-brightness) var(--tw-contrast) var(--tw-grayscale) var(--tw-hue-rotate) invert(100%) var(--tw-saturate) var(--tw-sepia) var(--tw-drop-shadow);filter:var(--tw-blur) var(--tw-brightness) var(--tw-contrast) var(--tw-grayscale) var(--tw-hue-rotate) var(--tw-invert) var(--tw-saturate) var(--tw-sepia) var(--tw-drop-shadow)}:is(.dark .hover\:dark\:bg-gray-700):hover{--tw-bg-opacity:1;background-color:#44403c;background-color:rgb(68 64 60/var(--tw-bg-opacity))}:is(.dark .hover\:dark\:bg-slate-700):hover{--tw-bg-opacity:1;background-color:#334155;background-color:rgb(51 65 85/var(--tw-bg-opacity))}:is(.dark .hover\:dark\:text-white):hover{--tw-text-opacity:1;color:#fff;color:rgb(255 255 255/var(--tw-text-opacity))}@media (min-width:768px){.md\:my-1{margin-bottom:.25rem;margin-top:.25rem}.md\:my-12{margin-bottom:3rem;margin-top:3rem}.md\:ml-\[-20\%\]{margin-left:-20%}.md\:mt-0{margin-top:0}.md\:mt-10{margin-top:2.5rem}.md\:mt-12{margin-top:3rem}.md\:block{display:block}.md\:flex{display:flex}.md\:hidden{display:none}.md\:w-1\/2{width:50%}.md\:w-1\/5{width:20%}.md\:w-3\/4{width:75%}.md\:w-40{width:10rem}.md\:w-\[140\%\]{width:140%}.md\:w-\[48\%\]{width:48%}.md\:flex-row{flex-direction:row}.md\:border-t-2{border-top-width:2px}.md\:p-0{padding:0}.md\:py-3{padding-bottom:.75rem;padding-top:.75rem}.md\:pt-0{padding-top:0}.md\:pt-6{padding-top:1.5rem}.md\:pt-8{padding-top:2rem}.md\:text-right{text-align:right}.md\:text-2xl{font-size:1.5rem;line-height:2rem}.md\:text-4xl{font-size:2.25rem;line-height:2.5rem}.md\:text-5xl{font-size:3rem;line-height:1}.md\:text-lg{font-size:1.125rem;line-height:1.75rem}.md\:text-sm{font-size:.875rem;line-height:1.25rem}.md\:text-xl{font-size:1.25rem;line-height:1.75rem}}.\[\&_a\]\:hover\:opacity-100:hover a{opacity:1}.\[\&_br\]\:hidden br{display:none}@media (min-width:768px){.\[\&_br\]\:md\:inline br{display:inline}}.\[\&_h1\]\:mt-12 h1{margin-top:3rem}.\[\&_h1\]\:mt-3 h1{margin-top:.75rem}.\[\&_h1\]\:hidden h1{display:none}@media (min-width:768px){.\[\&_h1\]\:md\:mt-4 h1{margin-top:1rem}}.\[\&_h2\]\:hidden h2{display:none}@media (min-width:768px){.\[\&_header\]\:md\:mx-\[-20\%\] header{margin-left:-20%;margin-right:-20%}.\[\&_header\]\:md\:max-w-\[140\%\] header{max-width:140%}}.\[\&_img\]\:hidden img{display:none}.\[\&_img\]\:hover\:scale-\[1\.02\]:hover img{--tw-scale-x:1.02;--tw-scale-y:1.02;transform:translate(var(--tw-translate-x),var(--tw-translate-y)) rotate(var(--tw-rotate)) skewX(var(--tw-skew-x)) skewY(var(--tw-skew-y)) scaleX(1.02) scaleY(1.02);transform:translate(var(--tw-translate-x),var(--tw-translate-y)) rotate(var(--tw-rotate)) skewX(var(--tw-skew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--tw-scale-y))}.\[\&_img\]\:hover\:opacity-40:hover img{opacity:.4}.\[\&_li\:nth-of-type\(1n\+7\)\]\:hidden li:nth-of-type(1n+7){display:none}.\[\&_p\]\:my-0 p{margin-bottom:0;margin-top:0}@media (min-width:768px){.\[\&_p_img\]\:md\:mx-\[-20\%\] p img{margin-left:-20%;margin-right:-20%}.\[\&_p_img\]\:md\:max-w-\[140\%\] p img{max-width:140%}.\[\&_pre\]\:md\:text-xs pre{font-size:.75rem;line-height:1rem}}</style>
<style>body{--tw-bg-opacity:1;background-color:#fafaf9;background-color:rgb(250 250 249/var(--tw-bg-opacity))}:is(.dark body){--tw-bg-opacity:1;background-color:#1c1917;background-color:rgb(28 25 23/var(--tw-bg-opacity))}p{line-height:1.6em;text-align:justify;text-justify:inter-word}a{text-decoration-color:rgba(0,0,0,.4)!important;transition:opacity .1s linear}a:hover{opacity:.4}h2 a{font-weight:900!important;text-decoration:none!important}h2 a:before{border-top:1px solid #000;content:"";display:block;max-width:100%;padding-bottom:.2em;width:100px}</style>
<link rel="stylesheet" href="/_nuxt/entry.860159ab.css">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/entry.132320c4.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/document-driven.0363b498.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/DocumentDrivenEmpty.e108496d.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/ContentRenderer.ab7aa593.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/ContentRendererMarkdown.vue.34a9b9e5.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/DocumentDrivenNotFound.1ae57909.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/head.2a60d7e2.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/default.da32a6bd.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/Navigator.367b0f88.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/Universe.8f6e7285.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/ContentDoc.8f593ddf.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/ContentQuery.7ad178f1.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/asyncData.c05490ab.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/Footer.01243a98.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/ContentRendererMarkdown.5e652ed9.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/IndexHeader.fc3e6e46.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/_plugin-vue_export-helper.c27b6911.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseH2.e8f9d61d.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseP.cc4cd5d0.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseA.3d26bf52.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/nuxt-link.05004bee.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/ShortNews.149ff603.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/ExperienceRow.71c0a4d5.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/slot.c16b83cf.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/node.e4a9c3bc.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseStrong.68dfba71.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/PublicationRow.e5ec229e.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseUl.261ffc4a.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseLi.74ff59f5.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/ContactItem.76061553.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/MarkdownHeader.4ad99717.js">
<link rel="prefetch" as="script" crossorigin href="/_nuxt/cards.8bcae384.js">
<link rel="prefetch" as="script" crossorigin href="/_nuxt/ContentList.8b93ffb1.js">
<link rel="prefetch" as="script" crossorigin href="/_nuxt/client-db.d4bf7640.js">
<link rel="prefetch" as="script" crossorigin href="/_nuxt/error-404.e7474b3b.js">
<link rel="prefetch" as="script" crossorigin href="/_nuxt/error-500.fb6a9f65.js">
<script type="module" src="/_nuxt/entry.132320c4.js" crossorigin></script><script>"use strict";(()=>{const a=window,e=document.documentElement,m=["dark","light"],c=window.localStorage.getItem("nuxt-color-mode")||"system";let n=c==="system"?f():c;const l=e.getAttribute("data-color-mode-forced");l&&(n=l),i(n),a["__NUXT_COLOR_MODE__"]={preference:c,value:n,getColorScheme:f,addColorScheme:i,removeColorScheme:d};function i(o){const t="--"+o+"",s="";e.classList?e.classList.add(t):e.className+=" "+t,s&&e.setAttribute("data-"+s,o)}function d(o){const t="--"+o+"",s="";e.classList?e.classList.remove(t):e.className=e.className.replace(new RegExp(t,"g"),""),s&&e.removeAttribute("data-"+s)}function r(o){return a.matchMedia("(prefers-color-scheme"+o+")")}function f(){if(a.matchMedia&&r("").media!=="not all"){for(const o of m)if(r(":"+o).matches)return o}return"light"}})();
</script></head>
<body ><div id="__nuxt"><!--[--><!----><!----><div class="document-driven-page"><!--[--><!--[--><div class="bg-transparent dark:bg-transparent hidden md:block text-normal px-4 py-2 text-gray-500 dark:text-gray-400 mx-auto bg-gray-100 dark:bg-gray-800"><div class="md:flex justify-between max-w-6xl mx-auto"><a class="text-xl font-bold hover:dark:text-white hover:text-black transition-colors" href="/"><span class="opacity-0"><img class="inline w-10 dark:invert transition-opacity opacity-60 hover:opacity-100" src="/assets/img/Universe.svg" alt=""></span></a><div class="flex flex-row justify-center"><!--[--><a class="pl-10 font-medium flex items-center" href="/"><span class="transition-border text-black dark:text-white border-b-2 border-b-gray-400">Home</span></a><a class="pl-10 font-medium flex items-center" href="/news/"><span class="transition-border hover:border-b-2 border-b-gray-400">News</span></a><a class="pl-10 font-medium flex items-center" href="/publication/"><span class="transition-border hover:border-b-2 border-b-gray-400">Publication</span></a><!--]--></div></div></div><div class="fixed flex md:hidden flex-row justify-between p-5 text-black dark:text-white bg-gray-100 dark:bg-gray-800 z-30 w-full top-0"><span class="text-xl font-bold">Home</span><span><img class="inline dark:invert" src="/assets/img/icons/menu.svg" alt=""></span></div><div class="flex md:hidden opacity-0 flex-row justify-between p-5 text-black dark:text-white bg-gray-100 dark:bg-gray-800 z-30 w-full top-0"><span class="text-xl font-bold">Home</span><span><img class="inline dark:invert" src="/assets/img/icons/menu.svg" alt=""></span></div><div class="translate-y-[-100vh] fixed w-full h-full top-0 left-0 z-20 bg-black transition-opacity opacity-0"></div><div class="duration-0 translate-y-[-100vh] opacity-0 md:hidden fixed flex flex-col justify-between w-full h-full top-0 left-0 bg-gray-100 dark:bg-gray-800 z-20 transition-transform duration-500"><div class="flex flex-col p-5 pt-24 text-xl text-gray-400 dark:text-gray-500"><!--[--><a class="transition-color py-3" href="/"><div class="flex justify-between"><span class="dark:text-white font-medium">Home</span><img class="opacity-100 dark:invert w-6 opacity-50" src="/assets/img/icons/arrow-right-bold.svg" alt=""></div></a><a class="transition-color py-3" href="/news/"><div class="flex justify-between"><span class="transition-border :border-b-4 border-b-gray-400">News</span><img class="dark:invert w-6 opacity-50" src="/assets/img/icons/arrow-right-bold.svg" alt=""></div></a><a class="transition-color py-3" href="/publication/"><div class="flex justify-between"><span class="transition-border :border-b-4 border-b-gray-400">Publication</span><img class="dark:invert w-6 opacity-50" src="/assets/img/icons/arrow-right-bold.svg" alt=""></div></a><!--]--></div><div class="text-gray-400 dark:text-gray-500 text-center py-4">Han Xue</div></div><!--]--><article class="pb-16 min-h-[100vh] [&amp;_header]:md:max-w-[140%] [&amp;_header]:md:mx-[-20%] [&amp;_pre]:md:text-xs font-serif"><!--[--><div class="prose dark:prose-invert mx-auto p-4 md:p-0 md:text-xl [&amp;_h1]:mt-12"><div class="mb-16"><div class="container md:w-[140%] md:ml-[-20%] px-0 md:pt-0"><div class="flex py-0 dark:text-white relative justify-end items-center mx-auto"><div class="w-[55%] hidden md:flex flex-col items-center justify-start shadow-lg p-12 py-8 z-20 h-fit absolute left-0 bg-neutral-100 dark:bg-neutral-700 bottom-16"><p class="w-full text-6xl py-4 m-0">Han Xue</p><p class="w-full text-xl pl-3 prose dark:prose-invert m-0"> 薛寒 <br> CS Ph.D. Candidate <a href="https://en.sjtu.edu.cn/">@SJTU</a> <br> Research Interests: Robotics, Computer Vision </p><p class="mt-4 w-full pl-3 m-0"><span class="m-0"><a href="mailto:xiaoxiaoxh@sjtu.edu.cn"><img class="inline dark:invert w-6 mr-3 opacity-75 hover:opacity-100 transition-opacity m-0" src="/assets/img/icons/email.svg" alt=""></a><a href="https://github.com/xiaoxiaoxh"><img class="inline dark:invert w-6 mr-3 opacity-75 hover:opacity-100 transition-opacity m-0" src="/assets/img/icons/github.svg" alt=""></a><a href="https://scholar.google.com.hk/citations?user=kQMFnUkAAAAJ"><img class="inline dark:invert w-6 mr-3 opacity-75 hover:opacity-100 transition-opacity m-0" src="/assets/img/icons/google-scholar.svg" alt=""></a><a href="https://twitter.com/HanXue012"><img class="inline dark:invert w-6 mr-3 opacity-75 hover:opacity-100 transition-opacity m-0" src="/assets/img/icons/twitter.svg" alt=""></a></span></p></div><img class="w-full md:w-1/2 shadow-lg my-0 md:my-12 z-10" src="/assets/img/hanxue.jpg" alt=""><div class="absolute h-full w-[75%] left-0 z-[-1]"></div><img class="hidden md:block absolute w-2/5 top-[-2.5rem] left-[2rem] dark:invert z-[-1] opacity-30" src="/assets/img/Universe.svg" alt=""></div></div><div class="hidden md:block w-full h-fit p-0 m-0 absolute mx-auto top-0 left-0 z-[-2] bg-neutral-200 dark:bg-neutral-800"><div class="max-w-prose mt-[3.4rem] opacity-0"><div class="container w-[140%] ml-[-20%] px-0 md:pt-0"><div class="flex py-0 dark:text-white relative justify-end items-center mx-auto"><img class="w-full md:w-1/2 shadow-lg my-12 z-10" src="/assets/img/hanxue.jpg" alt=""></div></div></div></div></div><h2 id="️-about-me"><a href="#️-about-me"><!--[-->🦸🏻‍♂️ About Me<!--]--></a></h2><p><!--[-->I am a fourth-year Computer Science Ph.D. candidate at <a href="https://en.sjtu.edu.cn/" rel="nofollow"><!--[-->Shanghai Jiao Tong University<!--]--></a> and a member of <a href="https://www.mvig.org/" rel="nofollow"><!--[-->Machine Intelligence and Vision Group (MVIG)<!--]--></a> under the supervision of <a href="https://www.mvig.org/" rel="nofollow"><!--[-->Prof. Cewu Lu<!--]--></a> (卢策吾). I am also a member of <a href="https://ai.sjtu.edu.cn/info/announcements/204" rel="nofollow"><!--[-->Wu Wen Jun Honorary Doctoral Program<!--]--></a> (吴文俊荣誉博士班).<!--]--></p><p><!--[-->I receive my bachelor degree from Shanghai Jiao Tong Universiy in 2021. My research interests lie in Robotics and Computer Vision. Previously, I have been working on deformable object perception and manipulation. Now I am particularly interested in imitation learning with tactile/force sensing and low-cost data collection system.<!--]--></p><p><!--[-->In the past, I have interned at <a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-asia/" rel="nofollow"><!--[-->Microsoft Research Asia<!--]--></a> under the supervsion of <a href="https://ancientmooner.github.io/" rel="nofollow"><!--[-->Han Hu<!--]--></a> and <a href="http://yue-cao.me/" rel="nofollow"><!--[-->Yue Cao<!--]--></a>. I also spent time with Prof. <a href="http://hxu.rocks/index.html" rel="nofollow"><!--[-->Huazhe Xu<!--]--></a> at Tsinghua University on my projects. In my spare time, I enjoy watching movies and playing with robots🤖.<!--]--></p><p><!--[-->I&#39;m on the job market now!<!--]--></p><h2 id="news"><a href="#news"><!--[-->📰 News<!--]--></a></h2><div class="[&amp;_li:nth-of-type(1n+7)]:hidden [&amp;_img]:hidden [&amp;_h1]:hidden [&amp;_h2]:hidden"><!--[--><div><!--[--><h1 class="dark:text-white text-center text-4xl md:text-5xl font-bold mb-0 mt-0 md:mt-10 max-w-5xl mx-auto">News</h1><h2 class="dark:text-gray-200 text-center text-xl font-normal my-6 max-w-4xl mx-auto">📢 Latest: One paper (DeformPAM) is accepted by ICRA 2025!</h2><!--]--><ul><!--[--><li><!--[--><strong><!--[-->06/18/2025<!--]--></strong> 🔥 <a href="https://reactive-diffusion-policy.github.io/" rel="nofollow"><!--[-->RDP<!--]--></a> is selected as the <strong><!--[-->Best Student Paper Award Finalist<!--]--></strong> @ RSS 2025!<!--]--></li><li><!--[--><strong><!--[-->05/23/2025<!--]--></strong> 🔥 <a href="https://reactive-diffusion-policy.github.io/" rel="nofollow"><!--[-->RDP<!--]--></a> is selected as the <strong><!--[-->Best Paper<!--]--></strong> in <a href="https://sites.google.com/view/icra-2025-beyond-pick-place/home" rel="nofollow"><!--[-->Beyond Pick and Place workshop<!--]--></a> @ ICRA 2025!<!--]--></li><li><!--[--><strong><!--[-->04/11/2025<!--]--></strong> 🎉 One paper (<a href="https://reactive-diffusion-policy.github.io/" rel="nofollow"><!--[-->Reactive Diffusion Policy<!--]--></a>) is accepted by RSS 2025!<!--]--></li><!--]--></ul><ul><!--[--><li><!--[--><strong><!--[-->01/29/2025<!--]--></strong> 🎉 One paper (<a href="https://deform-pam.robotflow.ai/" rel="nofollow"><!--[-->DeformPAM<!--]--></a>) is accepted by ICRA 2025!<!--]--></li><!--]--></ul><ul><!--[--><li><!--[--><strong><!--[-->08/31/2023<!--]--></strong> 🎉 One paper (<a href="https://unifolding.robotflow.ai/" rel="nofollow"><!--[-->UniFolding<!--]--></a>) is accepted by CoRL 2023!<!--]--></li><li><!--[--><strong><!--[-->07/14/2023<!--]--></strong> 🔥 One paper (<a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_ClothPose_A_Real-world_Benchmark_for_Visual_Analysis_of_Garment_Pose_ICCV_2023_paper.pdf" rel="nofollow"><!--[-->ClothPose<!--]--></a>) is accepted by ICCV 2023 as an <strong><!--[-->oral presentation<!--]--></strong>!<!--]--></li><li><!--[--><strong><!--[-->05/13/2023<!--]--></strong> 🎉 One paper (<a href="https://sites.google.com/view/rfuniverse" rel="nofollow"><!--[-->RFUniverse<!--]--></a>) is accepted by RSS 2023!<!--]--></li><li><!--[--><strong><!--[-->02/28/2023<!--]--></strong> 🎉 Two papers (<a href="https://garment-tracking.robotflow.ai/" rel="nofollow"><!--[-->GarmentTracking<!--]--></a> and <a href="https://sites.google.com/view/vtaco/" rel="nofollow"><!--[-->VTaCo<!--]--></a>) are accepted by CVPR 2023!<!--]--></li><!--]--></ul></div><!--]--></div><p><!--[--><a href="/news/" class=""><!--[-->More news &gt;&gt;&gt;<!--]--></a><!--]--></p><h2 id="experiences"><a href="#experiences"><!--[-->🏫 Experiences<!--]--></a></h2><div class="flex flex-row py-4 items-center my-5"><img id="publication-sjtu.png" class="mr-4 w-20 my-0" src="/assets/img/affiliation/sjtu.png" alt=""><div class="prose dark:prose-invert [&amp;_p]:my-0 md:text-lg"><!--[--><p><!--[--><strong><!--[-->Shanghai Jiao Tong University<!--]--></strong><br>
Ph.D. Student <br>
Research assistant in <a href="https://www.mvig.org/" rel="nofollow"><!--[-->Machine Intelligence and Vision Group (MVIG)<!--]--></a>, advised by <a href="https://www.mvig.org/" rel="nofollow"><!--[-->Prof. Cewu Lu<!--]--></a><br>
Sep. 2021 - Present<!--]--></p><!--]--></div></div><div class="flex flex-row py-4 items-center my-5"><img id="publication-microsoft.png" class="mr-4 w-20 my-0" src="/assets/img/affiliation/microsoft.png" alt=""><div class="prose dark:prose-invert [&amp;_p]:my-0 md:text-lg"><!--[--><p><!--[--><strong><!--[-->Microsoft Research Asia<!--]--></strong><br>
Research Intern, advised by <a href="https://ancientmooner.github.io/" rel="nofollow"><!--[-->Han Hu<!--]--></a> and <a href="http://yue-cao.me/" rel="nofollow"><!--[-->Yue Cao<!--]--></a>.<br>
Jul. 2019 - Mar. 2020<!--]--></p><!--]--></div></div><div class="flex flex-row py-4 items-center my-5"><img id="publication-sjtu.png" class="mr-4 w-20 my-0" src="/assets/img/affiliation/sjtu.png" alt=""><div class="prose dark:prose-invert [&amp;_p]:my-0 md:text-lg"><!--[--><p><!--[--><strong><!--[-->Shanghai Jiao Tong University<!--]--></strong><br>
Bachelor of Engineering in Computer Science. <br>
GPA 4.04/4.3, Rank 3/150 (Top 2%)<br>
Sep 2016 - Jun. 2021<!--]--></p><!--]--></div></div><h2 id="selected-publications"><a href="#selected-publications"><!--[-->📄 Selected Publications<!--]--></a></h2><div class="publication-row flex flex-col md:flex-row items-start mt-8 pb-8 border-b-2" type="conference"><div class="prose dark:prose-invert max-w-none font-normal"><div class="flex flex-wrap"><span><span class="mr-2 bg-gray-200 text-black py-[0.2em] text-sm px-2">RSS&#39;25</span></span><span class="mr-2">|</span><!--[--><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://reactive-diffusion-policy.github.io/">Website</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://arxiv.org/abs/2503.02881">arXiv</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://github.com/xiaoxiaoxh/reactive_diffusion_policy">Code</a></span><!--]--></div><div class="dark:text-white font-bold my-4 text-2xl md:text-2xl">Reactive Diffusion Policy: Slow-Fast Visual-Tactile Policy Learning for Contact-Rich Manipulation</div><div class="md:flex md:flex-row items-start"><img class="mr-4 w-full md:w-40 mt-1 mb-0 flex-grow-0" src="/assets/img/publications/rdp.gif" alt=""><div class="w-full mt-4 md:mt-0"><div class="text-lg"><!--[--><span><span class="font-bold dark:text-white underline">Han Xue*</span><span>, </span></span><span><span class="">Jieji Ren*</span><span>, </span></span><span><span class="">Wendi Chen*</span><span>, </span></span><span><span class="">Gu Zhang</span><span>, </span></span><span><span class="">Yuan Fang</span><span>, </span></span><span><span class="">Guoying Gu</span><span>, </span></span><span><span class="">Huazhe Xu†</span><span>, </span></span><span><span class="">Cewu Lu† (†Equal advising)</span><span> </span></span><!--]--></div><div class="text-gray-500 text-sm">Robotics: Science and Systems (RSS)</div><div class="prose dark:prose-invert [&amp;_p]:my-0"><!--[--><span class="text-red-600 font-bold">🔥 Best Student Paper Finalist.</span><!--]--></div></div></div></div></div><div class="publication-row flex flex-col md:flex-row items-start mt-8 pb-8 border-b-2" type="conference"><div class="prose dark:prose-invert max-w-none font-normal"><div class="flex flex-wrap"><span><span class="mr-2 bg-gray-200 text-black py-[0.2em] text-sm px-2">ICRA&#39;25</span></span><span class="mr-2">|</span><!--[--><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://deform-pam.robotflow.ai/">Website</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://arxiv.org/abs/2410.11584">arXiv</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://github.com/xiaoxiaoxh/DeformPAM">Code</a></span><!--]--></div><div class="dark:text-white font-bold my-4 text-2xl md:text-2xl">DeformPAM: Data-Efficient Learning for Long-horizon Deformable Object Manipulation via Preference-based Action Alignment</div><div class="md:flex md:flex-row items-start"><img class="mr-4 w-full md:w-40 mt-1 mb-0 flex-grow-0" src="/assets/img/publications/deform-pam.gif" alt=""><div class="w-full mt-4 md:mt-0"><div class="text-lg"><!--[--><span><span class="">Wendi Chen*</span><span>, </span></span><span><span class="font-bold dark:text-white underline">Han Xue*</span><span>, </span></span><span><span class="">Fangyuan Zhou</span><span>, </span></span><span><span class="">Yuan Fang</span><span>, </span></span><span><span class="">Cewu Lu (*Equal contribution)</span><span> </span></span><!--]--></div><div class="text-gray-500 text-sm">IEEE International Conference on Robotics and Automation (ICRA)</div><div class="prose dark:prose-invert [&amp;_p]:my-0"><!--[--><span class="text-red-600 font-bold">🔥 Best Paper Finalist <a href="https://deformable-workshop.github.io/icra2025/" rel="nofollow"><!--[-->@ RMDO Workshop in ICRA 2025<!--]--></a>.</span><!--]--></div></div></div></div></div><div class="publication-row flex flex-col md:flex-row items-start mt-8 pb-8 border-b-2" type="conference"><div class="prose dark:prose-invert max-w-none font-normal"><div class="flex flex-wrap"><span><span class="mr-2 bg-gray-200 text-black py-[0.2em] text-sm px-2">CoRL&#39;23</span></span><span class="mr-2">|</span><!--[--><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://openreview.net/pdf?id=ANJuNDFdvP">Proceeding</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://arxiv.org/abs/2311.01267">arXiv</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://github.com/xiaoxiaoxh/UniFolding">Code</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://unifolding.robotflow.ai/">Website</a></span><!--]--></div><div class="dark:text-white font-bold my-4 text-2xl md:text-2xl">UniFolding: Towards Sample-efficient, Scalable, and Generalizable Robotic Garment Folding</div><div class="md:flex md:flex-row items-start"><img class="mr-4 w-full md:w-40 mt-1 mb-0 flex-grow-0" src="/assets/img/publications/unifolding.gif" alt=""><div class="w-full mt-4 md:mt-0"><div class="text-lg"><!--[--><span><span class="font-bold dark:text-white underline">Han Xue*</span><span>, </span></span><span><span class="">Yutong Li*</span><span>, </span></span><span><span class="">Wenqiang Xu</span><span>, </span></span><span><span class="">Huanyu Li</span><span>, </span></span><span><span class="">Dongzhe Zheng</span><span>, </span></span><span><span class="">Cewu Lu (*Equal contribution)</span><span> </span></span><!--]--></div><div class="text-gray-500 text-sm">7th Annual Conference on Robot Learning.</div><div class="prose dark:prose-invert [&amp;_p]:my-0"><!--[--><!--]--></div></div></div></div></div><div class="publication-row flex flex-col md:flex-row items-start mt-8 pb-8 border-b-2" type="conference"><div class="prose dark:prose-invert max-w-none font-normal"><div class="flex flex-wrap"><span><span class="mr-2 bg-gray-200 text-black py-[0.2em] text-sm px-2">ICCV&#39;23</span></span><span class="mr-2">|</span><!--[--><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_ClothPose_A_Real-world_Benchmark_for_Visual_Analysis_of_Garment_Pose_ICCV_2023_paper.pdf">Proceeding</a></span><!--]--></div><div class="dark:text-white font-bold my-4 text-2xl md:text-2xl">ClothPose: A Real-world Benchmark for Visual Analysis of Garment Pose via An Indirect Recording Solution</div><div class="md:flex md:flex-row items-start"><img class="mr-4 w-full md:w-40 mt-1 mb-0 flex-grow-0" src="/assets/img/publications/clothpose.png" alt=""><div class="w-full mt-4 md:mt-0"><div class="text-lg"><!--[--><span><span class="">Wenqiang Xu*</span><span>, </span></span><span><span class="">Wenxin Du*</span><span>, </span></span><span><span class="font-bold dark:text-white underline">Han Xue</span><span>, </span></span><span><span class="">Yutong Li</span><span>, </span></span><span><span class="">Ruolin Ye</span><span>, </span></span><span><span class="">Yan-Feng Wang</span><span>, </span></span><span><span class="">Cewu Lu (*Equal contribution)</span><span> </span></span><!--]--></div><div class="text-gray-500 text-sm">Proceedings of the IEEE/CVF International Conference on Computer Vision</div><div class="prose dark:prose-invert [&amp;_p]:my-0"><!--[--><span class="text-red-600 font-bold">🔥 Oral Presentation.</span><!--]--></div></div></div></div></div><div class="publication-row flex flex-col md:flex-row items-start mt-8 pb-8 border-b-2" type="conference"><div class="prose dark:prose-invert max-w-none font-normal"><div class="flex flex-wrap"><span><span class="mr-2 bg-gray-200 text-black py-[0.2em] text-sm px-2">CVPR&#39;23</span></span><span class="mr-2">|</span><!--[--><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://openaccess.thecvf.com/content/CVPR2023/papers/Xue_GarmentTracking_Category-Level_Garment_Pose_Tracking_CVPR_2023_paper.pdf">Proceeding</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://arxiv.org/pdf/2303.13913.pdf">arXiv</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://github.com/xiaoxiaoxh/GarmentTracking">Code</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://garment-tracking.robotflow.ai/">Website</a></span><!--]--></div><div class="dark:text-white font-bold my-4 text-2xl md:text-2xl">GarmentTracking: Category-Level Garment Pose Tracking</div><div class="md:flex md:flex-row items-start"><img class="mr-4 w-full md:w-40 mt-1 mb-0 flex-grow-0" src="/assets/img/publications/garment-tracking.gif" alt=""><div class="w-full mt-4 md:mt-0"><div class="text-lg"><!--[--><span><span class="font-bold dark:text-white underline">Han Xue</span><span>, </span></span><span><span class="">Wenqiang Xu</span><span>, </span></span><span><span class="">Jieyi Zhang</span><span>, </span></span><span><span class="">Tutian Tang</span><span>, </span></span><span><span class="">Yutong Li</span><span>, </span></span><span><span class="">Wenxin Du</span><span>, </span></span><span><span class="">Ruolin Ye</span><span>, </span></span><span><span class="">Cewu Lu</span><span> </span></span><!--]--></div><div class="text-gray-500 text-sm">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition.</div><div class="prose dark:prose-invert [&amp;_p]:my-0"><!--[--><!--]--></div></div></div></div></div><div class="publication-row flex flex-col md:flex-row items-start mt-8 pb-8 border-b-2" type="conference"><div class="prose dark:prose-invert max-w-none font-normal"><div class="flex flex-wrap"><span><span class="mr-2 bg-gray-200 text-black py-[0.2em] text-sm px-2">CVPR&#39;23</span></span><span class="mr-2">|</span><!--[--><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://openaccess.thecvf.com/content/CVPR2023/papers/Xu_Visual-Tactile_Sensing_for_In-Hand_Object_Reconstruction_CVPR_2023_paper.pdf">Proceeding</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://arxiv.org/pdf/2303.14498.pdf">arXiv</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://github.com/jeffsonyu/VTacO">Code</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://sites.google.com/view/vtaco/">Website</a></span><!--]--></div><div class="dark:text-white font-bold my-4 text-2xl md:text-2xl">Visual-Tactile Sensing for In-Hand Object Reconstruction</div><div class="md:flex md:flex-row items-start"><img class="mr-4 w-full md:w-40 mt-1 mb-0 flex-grow-0" src="/assets/img/publications/vtaco.png" alt=""><div class="w-full mt-4 md:mt-0"><div class="text-lg"><!--[--><span><span class="">Wenqiang Xu*</span><span>, </span></span><span><span class="">Zhenjun Yu*</span><span>, </span></span><span><span class="font-bold dark:text-white underline">Han Xue</span><span>, </span></span><span><span class="">Ruolin Ye</span><span>, </span></span><span><span class="">Siqiong Yao</span><span>, </span></span><span><span class="">Cewu Lu (*Equal contribution)</span><span> </span></span><!--]--></div><div class="text-gray-500 text-sm">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition.</div><div class="prose dark:prose-invert [&amp;_p]:my-0"><!--[--><!--]--></div></div></div></div></div><div class="publication-row flex flex-col md:flex-row items-start mt-8 pb-8 border-b-2" type="conference"><div class="prose dark:prose-invert max-w-none font-normal"><div class="flex flex-wrap"><span><span class="mr-2 bg-gray-200 text-black py-[0.2em] text-sm px-2">RSS&#39;23</span></span><span class="mr-2">|</span><!--[--><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://www.roboticsproceedings.org/rss19/p087.pdf">Proceeding</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://github.com/mvig-robotflow/pyrfuniverse">Code</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://sites.google.com/view/rfuniverse">Website</a></span><!--]--></div><div class="dark:text-white font-bold my-4 text-2xl md:text-2xl">Demonstrating RFUniverse: A Multiphysics Simulation Platform for Embodied AI</div><div class="md:flex md:flex-row items-start"><img class="mr-4 w-full md:w-40 mt-1 mb-0 flex-grow-0" src="/assets/img/publications/rfuniverse.png" alt=""><div class="w-full mt-4 md:mt-0"><div class="text-lg"><!--[--><span><span class="">Haoyuan Fu*</span><span>, </span></span><span><span class="">Wenqiang Xu*</span><span>, </span></span><span><span class="">Ruolin Ye*</span><span>, </span></span><span><span class="font-bold dark:text-white underline">Han Xue</span><span>, </span></span><span><span class="">Zhenjun Yu</span><span>, </span></span><span><span class="">Tutian Tang</span><span>, </span></span><span><span class="">Yutong Li</span><span>, </span></span><span><span class="">Wenxin Du</span><span>, </span></span><span><span class="">Jieyi Zhang</span><span>, </span></span><span><span class="">Cewu Lu (*Equal contribution)</span><span> </span></span><!--]--></div><div class="text-gray-500 text-sm">Robotics: Science and Systems.</div><div class="prose dark:prose-invert [&amp;_p]:my-0"><!--[--><!--]--></div></div></div></div></div><div class="publication-row flex flex-col md:flex-row items-start mt-8 pb-8 border-b-2" type="journal"><div class="prose dark:prose-invert max-w-none font-normal"><div class="flex flex-wrap"><span><span class="mr-2 bg-gray-200 text-black py-[0.2em] text-sm px-2">TIP&#39;22</span></span><span class="mr-2">|</span><!--[--><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://arxiv.org/pdf/2105.03260">arXiv</a></span><!--]--></div><div class="dark:text-white font-bold my-4 text-2xl md:text-2xl">Toward Real-World Category-Level Articulation Pose Estimation</div><div class="md:flex md:flex-row items-start"><img class="mr-4 w-full md:w-40 mt-1 mb-0 flex-grow-0" src="/assets/img/publications/articulation_real.png" alt=""><div class="w-full mt-4 md:mt-0"><div class="text-lg"><!--[--><span><span class="">Liu Liu*</span><span>, </span></span><span><span class="font-bold dark:text-white underline">Han Xue*</span><span>, </span></span><span><span class="">Wenqiang Xu</span><span>, </span></span><span><span class="">Haoyuan Fu</span><span>, </span></span><span><span class="">Cewu Lu (*Equal contribution)</span><span> </span></span><!--]--></div><div class="text-gray-500 text-sm">IEEE Transactions on Image Processing.</div><div class="prose dark:prose-invert [&amp;_p]:my-0"><!--[--><!--]--></div></div></div></div></div><div class="publication-row flex flex-col md:flex-row items-start mt-8 pb-8 border-b-2" type="conference"><div class="prose dark:prose-invert max-w-none font-normal"><div class="flex flex-wrap"><span><span class="mr-2 bg-gray-200 text-black py-[0.2em] text-sm px-2">BMVC&#39;21</span></span><span class="mr-2">|</span><!--[--><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://www.bmvc2021-virtualconference.com/assets/papers/0544.pdf">Proceeding</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://arxiv.org/pdf/2112.07334.pdf">arXiv</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://github.com/xiaoxiaoxh/OMAD">Code</a></span><!--]--></div><div class="dark:text-white font-bold my-4 text-2xl md:text-2xl">OMAD: Object Model with Articulated Deformations for Pose Estimation and Retrieval</div><div class="md:flex md:flex-row items-start"><img class="mr-4 w-full md:w-40 mt-1 mb-0 flex-grow-0" src="/assets/img/publications/omad.png" alt=""><div class="w-full mt-4 md:mt-0"><div class="text-lg"><!--[--><span><span class="font-bold dark:text-white underline">Han Xue*</span><span>, </span></span><span><span class="">Liu Liu*</span><span>, </span></span><span><span class="">Wenqiang Xu</span><span>, </span></span><span><span class="">Haoyuan Fu</span><span>, </span></span><span><span class="">Cewu Lu (*Equal contribution)</span><span> </span></span><!--]--></div><div class="text-gray-500 text-sm">The 32nd British Machine Vision Conference.</div><div class="prose dark:prose-invert [&amp;_p]:my-0"><!--[--><!--]--></div></div></div></div></div><div class="publication-row flex flex-col md:flex-row items-start mt-8 pb-8 border-b-2" type="conference"><div class="prose dark:prose-invert max-w-none font-normal"><div class="flex flex-wrap"><span><span class="mr-2 bg-gray-200 text-black py-[0.2em] text-sm px-2">ECCV&#39;20</span></span><span class="mr-2">|</span><!--[--><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123660222.pdf">Proceeding</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://arxiv.org/pdf/1912.11473.pdf">arXiv</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://github.com/justimyhxu/Dense-RepPoints">Code</a></span><!--]--></div><div class="dark:text-white font-bold my-4 text-2xl md:text-2xl">Dense RepPoints: Representing Visual Objects with Dense Point Sets</div><div class="md:flex md:flex-row items-start"><img class="mr-4 w-full md:w-40 mt-1 mb-0 flex-grow-0" src="/assets/img/publications/dense_reppoints.jpg" alt=""><div class="w-full mt-4 md:mt-0"><div class="text-lg"><!--[--><span><span class="">Ze Yang*</span><span>, </span></span><span><span class="">Yinghao Xu*</span><span>, </span></span><span><span class="font-bold dark:text-white underline">Han Xue*</span><span>, </span></span><span><span class="">Zheng Zhang</span><span>, </span></span><span><span class="">Raquel Urtasun</span><span>, </span></span><span><span class="">Liwei Wang</span><span>, </span></span><span><span class="">Stephen Lin</span><span>, </span></span><span><span class="">Han Hu (*Equal contribution)</span><span> </span></span><!--]--></div><div class="text-gray-500 text-sm">The European Conference on Computer Vision.</div><div class="prose dark:prose-invert [&amp;_p]:my-0"><!--[--><!--]--></div></div></div></div></div><div class="publication-row flex flex-col md:flex-row items-start mt-8 pb-8" type="conference"><div class="prose dark:prose-invert max-w-none font-normal"><div class="flex flex-wrap"><span><span class="mr-2 bg-gray-200 text-black py-[0.2em] text-sm px-2">CVPR&#39;18</span></span><span class="mr-2">|</span><!--[--><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Chen_LiDAR-Video_Driving_Dataset_CVPR_2018_paper.pdf">Proceeding</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://github.com/driving-behavior/DBNet">Code</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="http://www.dbehavior.net/">Website</a></span><!--]--></div><div class="dark:text-white font-bold my-4 text-2xl md:text-2xl">Lidar-video driving dataset: Learning driving policies effectively</div><div class="md:flex md:flex-row items-start"><img class="mr-4 w-full md:w-40 mt-1 mb-0 flex-grow-0" src="/assets/img/publications/dbnet.jpg" alt=""><div class="w-full mt-4 md:mt-0"><div class="text-lg"><!--[--><span><span class="">Yiping Chen*</span><span>, </span></span><span><span class="">Jingkang Wang*</span><span>, </span></span><span><span class="">Jonathan Li</span><span>, </span></span><span><span class="">Cewu Lu</span><span>, </span></span><span><span class="">Zhipeng Luo</span><span>, </span></span><span><span class="font-bold dark:text-white underline">Han Xue</span><span>, </span></span><span><span class="">Cheng Wang (*Equal contribution)</span><span> </span></span><!--]--></div><div class="text-gray-500 text-sm">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.</div><div class="prose dark:prose-invert [&amp;_p]:my-0"><!--[--><!--]--></div></div></div></div></div><p><!--[--><a href="/publication/" class=""><!--[-->Full publication list &gt;&gt;&gt;<!--]--></a><!--]--></p><h2 id="talks"><a href="#talks"><!--[-->✨ Talks<!--]--></a></h2><ul><!--[--><li><!--[-->[Apr. 2025] Invited talk @ <a href="https://www.techbeat.net/" rel="nofollow"><!--[-->TechBeat<!--]--></a> (将门创投) on &quot;Robotic Imitation Learning with Vision-Tactile/Force Sensing&quot;. The link of the recorded video is <a href="https://www.techbeat.net/talk-info?id=963" rel="nofollow"><!--[-->here<!--]--></a>.<!--]--></li><li><!--[-->[Dec. 2024] Invited talk @ <a href="https://www.roscon.cn/2024/index.html" rel="nofollow"><!--[-->ROSCon China 2024<!--]--></a> workshop on &quot;Development Trends and Challenges in Embodied AI&quot;. The link of the recorded video is <a href="https://www.bilibili.com/video/BV1Z3cteAEnD/?spm_id_from=333.337.search-card.all.click&amp;vd_source=8e062051896958b92b4759e0f4753657" rel="nofollow"><!--[-->here<!--]--></a>.<!--]--></li><li><!--[-->[Oct. 2024] Invited talk @ <a href="http://hxu.rocks/index.html" rel="nofollow"><!--[-->TEA lab<!--]--></a> in Tsinghua University, IIIS on &quot;Efficient Learning for Long-horizon Deformable Object Manipulation&quot;<!--]--></li><!--]--></ul><h2 id="awards"><a href="#awards"><!--[-->🏆 Awards<!--]--></a></h2><ul><!--[--><li><!--[-->Outstanding Graduates in Shanghai (Top 3%) [上海市优秀毕业生] in 2021.<!--]--></li><li><!--[-->Rongchang Technology Innovation Scholarship (Top 10 students in SJTU) [荣昶科技创新奖学金] in 2020.<!--]--></li><li><!--[-->SenseTime Scholarship (Top 21 undergraduates in China) [商汤奖学金] in 2020.<!--]--></li><li><!--[-->National Scholarship (Top 3 students in CS Department) in 2017, 2018 and 2019 (three consecutive years) [国家奖学金（连续三年）].<!--]--></li><li><!--[-->Academic Excellence Scholarship (Class A) of SJTU (Top 1% in SJTU) in 2018.<!--]--></li><li><!--[-->Meritorious Winner Prize of Mathematical Contest in Modeling in 2018.<!--]--></li><li><!--[-->1st Prize in China Undergraduate Mathematical Contest in Modeling (Shanghai Division) in 2017.<!--]--></li><!--]--></ul><h2 id="find-me"><a href="#find-me"><!--[-->📧 Find Me<!--]--></a></h2><span><a href="mailto:xiaoxiaoxh@sjtu.edu.cn" class="mr-4"><img class="w-6 inline dark:invert mr-2 my-0" src="/assets/img/icons/email.svg" alt=""><!--[-->Email<!--]--></a></span><span><a href="https://github.com/xiaoxiaoxh" class="mr-4"><img class="w-6 inline dark:invert mr-2 my-0" src="/assets/img/icons/github.svg" alt=""><!--[-->GitHub<!--]--></a></span><span><a href="https://twitter.com/HanXue012" class="mr-4"><img class="w-6 inline dark:invert mr-2 my-0" src="/assets/img/icons/twitter.svg" alt=""><!--[-->Twitter<!--]--></a></span></div><!--]--></article><div class="bg-gray-100 dark:bg-gray-800 py-4"><div class="prose mx-auto dark:prose-invert p-4 md:text-lg opacity-60"><div class="flex-col md:flex-row flex justify-between border-b-2 border-b-gray-300"><div><p class="text-sm"> 薛寒 | Han Xue <br> CS Ph.D. Candidate <a href="https://en.sjtu.edu.cn/">@SJTU</a> <br> Research Interests: Robotics, Computer Vision </p></div><div><p class="text-sm md:text-right [&amp;_br]:hidden [&amp;_br]:md:inline"><a href="mailto:xiaoxiaoxh@sjtu.edu.cn">E-Mail</a> <br><a href="https://github.com/xiaoxiaoxh">GitHub</a> <br><a href="https://twitter.com/HanXue012">Twitter</a> <br></p></div></div><div class="text-gray-500 dark:text-gray-400 mx-auto text-sm"><p> © <a href="https://hanxue.me">Han Xue</a> 2025. Last updated: 2025/6/19. Use my website <a class="underline" href="https://github.com/YiqinZhao/yiqinzhao.me-source">template made by Yiqin Zhao</a>. </p></div></div></div><!--]--></div><!--]--></div><script type="application/json" id="__NUXT_DATA__" data-ssr="true" data-src="/_payload.json">[{"state":1,"_errors":576,"serverRendered":5,"path":11,"prerenderedAt":578},["Reactive",2],{"$scolor-mode":3,"$sdd-pages":7,"$sdd-surrounds":557,"$sdd-globals":568,"$sdd-navigation":570},{"preference":4,"value":4,"unknown":5,"forced":6},"system",true,false,["ShallowRef",8],["ShallowReactive",9],{"/":10},{"_path":11,"_dir":12,"_draft":6,"_partial":6,"_locale":12,"title":13,"description":12,"hideTitle":5,"disableFancyImage":5,"body":14,"_type":551,"_id":552,"_source":553,"_file":554,"_extension":555,"layout":556},"/","","Home",{"type":15,"children":16,"toc":541},"root",[17,22,30,73,78,119,124,130,134,143,149,190,224,249,255,277,302,310,327,335,342,350,359,367,375,384,393,399,460,466,504,510,521,531],{"type":18,"tag":19,"props":20,"children":21},"element","IndexHeader",{},[],{"type":18,"tag":23,"props":24,"children":26},"h2",{"id":25},"️-about-me",[27],{"type":28,"value":29},"text","🦸🏻‍♂️ About Me",{"type":18,"tag":31,"props":32,"children":33},"p",{},[34,36,45,47,54,56,62,64,71],{"type":28,"value":35},"I am a fourth-year Computer Science Ph.D. candidate at ",{"type":18,"tag":37,"props":38,"children":42},"a",{"href":39,"rel":40},"https://en.sjtu.edu.cn/",[41],"nofollow",[43],{"type":28,"value":44},"Shanghai Jiao Tong University",{"type":28,"value":46}," and a member of ",{"type":18,"tag":37,"props":48,"children":51},{"href":49,"rel":50},"https://www.mvig.org/",[41],[52],{"type":28,"value":53},"Machine Intelligence and Vision Group (MVIG)",{"type":28,"value":55}," under the supervision of ",{"type":18,"tag":37,"props":57,"children":59},{"href":49,"rel":58},[41],[60],{"type":28,"value":61},"Prof. Cewu Lu",{"type":28,"value":63}," (卢策吾). I am also a member of ",{"type":18,"tag":37,"props":65,"children":68},{"href":66,"rel":67},"https://ai.sjtu.edu.cn/info/announcements/204",[41],[69],{"type":28,"value":70},"Wu Wen Jun Honorary Doctoral Program",{"type":28,"value":72}," (吴文俊荣誉博士班).",{"type":18,"tag":31,"props":74,"children":75},{},[76],{"type":28,"value":77},"I receive my bachelor degree from Shanghai Jiao Tong Universiy in 2021. My research interests lie in Robotics and Computer Vision. Previously, I have been working on deformable object perception and manipulation. Now I am particularly interested in imitation learning with tactile/force sensing and low-cost data collection system.",{"type":18,"tag":31,"props":79,"children":80},{},[81,83,90,92,99,101,108,110,117],{"type":28,"value":82},"In the past, I have interned at ",{"type":18,"tag":37,"props":84,"children":87},{"href":85,"rel":86},"https://www.microsoft.com/en-us/research/lab/microsoft-research-asia/",[41],[88],{"type":28,"value":89},"Microsoft Research Asia",{"type":28,"value":91}," under the supervsion of ",{"type":18,"tag":37,"props":93,"children":96},{"href":94,"rel":95},"https://ancientmooner.github.io/",[41],[97],{"type":28,"value":98},"Han Hu",{"type":28,"value":100}," and ",{"type":18,"tag":37,"props":102,"children":105},{"href":103,"rel":104},"http://yue-cao.me/",[41],[106],{"type":28,"value":107},"Yue Cao",{"type":28,"value":109},". I also spent time with Prof. ",{"type":18,"tag":37,"props":111,"children":114},{"href":112,"rel":113},"http://hxu.rocks/index.html",[41],[115],{"type":28,"value":116},"Huazhe Xu",{"type":28,"value":118}," at Tsinghua University on my projects. In my spare time, I enjoy watching movies and playing with robots🤖.",{"type":18,"tag":31,"props":120,"children":121},{},[122],{"type":28,"value":123},"I'm on the job market now!",{"type":18,"tag":23,"props":125,"children":127},{"id":126},"news",[128],{"type":28,"value":129},"📰 News",{"type":18,"tag":131,"props":132,"children":133},"ShortNews",{},[],{"type":18,"tag":31,"props":135,"children":136},{},[137],{"type":18,"tag":37,"props":138,"children":140},{"href":139},"/news/",[141],{"type":28,"value":142},"More news >>>",{"type":18,"tag":23,"props":144,"children":146},{"id":145},"experiences",[147],{"type":28,"value":148},"🏫 Experiences",{"type":18,"tag":150,"props":151,"children":153},"ExperienceRow",{"icon":152},"sjtu.png",[154],{"type":18,"tag":31,"props":155,"children":156},{},[157,162,166,168,171,173,178,180,185,188],{"type":18,"tag":158,"props":159,"children":160},"strong",{},[161],{"type":28,"value":44},{"type":18,"tag":163,"props":164,"children":165},"br",{},[],{"type":28,"value":167},"\nPh.D. Student ",{"type":18,"tag":163,"props":169,"children":170},{},[],{"type":28,"value":172},"\nResearch assistant in ",{"type":18,"tag":37,"props":174,"children":176},{"href":49,"rel":175},[41],[177],{"type":28,"value":53},{"type":28,"value":179},", advised by ",{"type":18,"tag":37,"props":181,"children":183},{"href":49,"rel":182},[41],[184],{"type":28,"value":61},{"type":18,"tag":163,"props":186,"children":187},{},[],{"type":28,"value":189},"\nSep. 2021 - Present",{"type":18,"tag":150,"props":191,"children":193},{"icon":192},"microsoft.png",[194],{"type":18,"tag":31,"props":195,"children":196},{},[197,201,204,206,211,212,217,219,222],{"type":18,"tag":158,"props":198,"children":199},{},[200],{"type":28,"value":89},{"type":18,"tag":163,"props":202,"children":203},{},[],{"type":28,"value":205},"\nResearch Intern, advised by ",{"type":18,"tag":37,"props":207,"children":209},{"href":94,"rel":208},[41],[210],{"type":28,"value":98},{"type":28,"value":100},{"type":18,"tag":37,"props":213,"children":215},{"href":103,"rel":214},[41],[216],{"type":28,"value":107},{"type":28,"value":218},".",{"type":18,"tag":163,"props":220,"children":221},{},[],{"type":28,"value":223},"\nJul. 2019 - Mar. 2020",{"type":18,"tag":150,"props":225,"children":226},{"icon":152},[227],{"type":18,"tag":31,"props":228,"children":229},{},[230,234,237,239,242,244,247],{"type":18,"tag":158,"props":231,"children":232},{},[233],{"type":28,"value":44},{"type":18,"tag":163,"props":235,"children":236},{},[],{"type":28,"value":238},"\nBachelor of Engineering in Computer Science. ",{"type":18,"tag":163,"props":240,"children":241},{},[],{"type":28,"value":243},"\nGPA 4.04/4.3, Rank 3/150 (Top 2%)",{"type":18,"tag":163,"props":245,"children":246},{},[],{"type":28,"value":248},"\nSep 2016 - Jun. 2021",{"type":18,"tag":23,"props":250,"children":252},{"id":251},"selected-publications",[253],{"type":28,"value":254},"📄 Selected Publications",{"type":18,"tag":256,"props":257,"children":264},"PublicationRow",{":artifactLinks":258,":authors":259,":venue":260,"thumbnail":261,"title":262,"type":263},"{\"Website\":\"https://reactive-diffusion-policy.github.io/\",\"arXiv\":\"https://arxiv.org/abs/2503.02881\",\"Code\":\"https://github.com/xiaoxiaoxh/reactive_diffusion_policy\"}","[\"Han Xue*\",\"Jieji Ren*\",\"Wendi Chen*\",\"Gu Zhang\",\"Yuan Fang\",\"Guoying Gu\",\"Huazhe Xu†\",\"Cewu Lu† (†Equal advising)\"]","{\"acronym\":\"RSS\",\"year\":2025,\"name\":\"Robotics: Science and Systems (RSS)\"}","rdp.gif","Reactive Diffusion Policy: Slow-Fast Visual-Tactile Policy Learning for Contact-Rich Manipulation","conference",[265],{"type":18,"tag":31,"props":266,"children":267},{},[268],{"type":18,"tag":269,"props":270,"children":274},"span",{"className":271},[272,273],"text-red-600","font-bold",[275],{"type":28,"value":276},"🔥 Best Student Paper Finalist.",{"type":18,"tag":256,"props":278,"children":284},{":artifactLinks":279,":authors":280,":venue":281,"thumbnail":282,"title":283,"type":263},"{\"Website\":\"https://deform-pam.robotflow.ai/\",\"arXiv\":\"https://arxiv.org/abs/2410.11584\",\"Code\":\"https://github.com/xiaoxiaoxh/DeformPAM\"}","[\"Wendi Chen*\",\"Han Xue*\",\"Fangyuan Zhou\",\"Yuan Fang\",\"Cewu Lu (*Equal contribution)\"]","{\"acronym\":\"ICRA\",\"year\":2025,\"name\":\"IEEE International Conference on Robotics and Automation (ICRA)\"}","deform-pam.gif","DeformPAM: Data-Efficient Learning for Long-horizon Deformable Object Manipulation via Preference-based Action Alignment",[285],{"type":18,"tag":31,"props":286,"children":287},{},[288],{"type":18,"tag":269,"props":289,"children":291},{"className":290},[272,273],[292,294,301],{"type":28,"value":293},"🔥 Best Paper Finalist ",{"type":18,"tag":37,"props":295,"children":298},{"href":296,"rel":297},"https://deformable-workshop.github.io/icra2025/",[41],[299],{"type":28,"value":300},"@ RMDO Workshop in ICRA 2025",{"type":28,"value":218},{"type":18,"tag":256,"props":303,"children":309},{":artifactLinks":304,":authors":305,":venue":306,"thumbnail":307,"title":308,"type":263},"{\"Proceeding\":\"https://openreview.net/pdf?id=ANJuNDFdvP\",\"arXiv\":\"https://arxiv.org/abs/2311.01267\",\"Code\":\"https://github.com/xiaoxiaoxh/UniFolding\",\"Website\":\"https://unifolding.robotflow.ai/\"}","[\"Han Xue*\",\"Yutong Li*\",\"Wenqiang Xu\",\"Huanyu Li\",\"Dongzhe Zheng\",\"Cewu Lu (*Equal contribution)\"]","{\"acronym\":\"CoRL\",\"year\":2023,\"name\":\"7th Annual Conference on Robot Learning.\"}","unifolding.gif","UniFolding: Towards Sample-efficient, Scalable, and Generalizable Robotic Garment Folding",[],{"type":18,"tag":256,"props":311,"children":317},{":artifactLinks":312,":authors":313,":venue":314,"thumbnail":315,"title":316,"type":263},"{\"Proceeding\":\"https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_ClothPose_A_Real-world_Benchmark_for_Visual_Analysis_of_Garment_Pose_ICCV_2023_paper.pdf\"}","[\"Wenqiang Xu*\",\"Wenxin Du*\",\"Han Xue\",\"Yutong Li\",\"Ruolin Ye\",\"Yan-Feng Wang\",\"Cewu Lu (*Equal contribution)\"]","{\"acronym\":\"ICCV\",\"year\":2023,\"name\":\"Proceedings of the IEEE/CVF International Conference on Computer Vision\"}","clothpose.png","ClothPose: A Real-world Benchmark for Visual Analysis of Garment Pose via An Indirect Recording Solution",[318],{"type":18,"tag":31,"props":319,"children":320},{},[321],{"type":18,"tag":269,"props":322,"children":324},{"className":323},[272,273],[325],{"type":28,"value":326},"🔥 Oral Presentation.",{"type":18,"tag":256,"props":328,"children":334},{":artifactLinks":329,":authors":330,":venue":331,"thumbnail":332,"title":333,"type":263},"{\"Proceeding\":\"https://openaccess.thecvf.com/content/CVPR2023/papers/Xue_GarmentTracking_Category-Level_Garment_Pose_Tracking_CVPR_2023_paper.pdf\",\"arXiv\":\"https://arxiv.org/pdf/2303.13913.pdf\",\"Code\":\"https://github.com/xiaoxiaoxh/GarmentTracking\",\"Website\":\"https://garment-tracking.robotflow.ai/\"}","[\"Han Xue\",\"Wenqiang Xu\",\"Jieyi Zhang\",\"Tutian Tang\",\"Yutong Li\",\"Wenxin Du\",\"Ruolin Ye\",\"Cewu Lu\"]","{\"acronym\":\"CVPR\",\"year\":2023,\"name\":\"Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition.\"}","garment-tracking.gif","GarmentTracking: Category-Level Garment Pose Tracking",[],{"type":18,"tag":256,"props":336,"children":341},{":artifactLinks":337,":authors":338,":venue":331,"thumbnail":339,"title":340,"type":263},"{\"Proceeding\":\"https://openaccess.thecvf.com/content/CVPR2023/papers/Xu_Visual-Tactile_Sensing_for_In-Hand_Object_Reconstruction_CVPR_2023_paper.pdf\",\"arXiv\":\"https://arxiv.org/pdf/2303.14498.pdf\",\"Code\":\"https://github.com/jeffsonyu/VTacO\",\"Website\":\"https://sites.google.com/view/vtaco/\"}","[\"Wenqiang Xu*\",\"Zhenjun Yu*\",\"Han Xue\",\"Ruolin Ye\",\"Siqiong Yao\",\"Cewu Lu (*Equal contribution)\"]","vtaco.png","Visual-Tactile Sensing for In-Hand Object Reconstruction",[],{"type":18,"tag":256,"props":343,"children":349},{":artifactLinks":344,":authors":345,":venue":346,"thumbnail":347,"title":348,"type":263},"{\"Proceeding\":\"https://www.roboticsproceedings.org/rss19/p087.pdf\",\"Code\":\"https://github.com/mvig-robotflow/pyrfuniverse\",\"Website\":\"https://sites.google.com/view/rfuniverse\"}","[\"Haoyuan Fu*\",\"Wenqiang Xu*\",\"Ruolin Ye*\",\"Han Xue\",\"Zhenjun Yu\",\"Tutian Tang\",\"Yutong Li\",\"Wenxin Du\",\"Jieyi Zhang\",\"Cewu Lu (*Equal contribution)\"]","{\"acronym\":\"RSS\",\"year\":2023,\"name\":\"Robotics: Science and Systems.\"}","rfuniverse.png","Demonstrating RFUniverse: A Multiphysics Simulation Platform for Embodied AI",[],{"type":18,"tag":256,"props":351,"children":358},{":artifactLinks":352,":authors":353,":venue":354,"thumbnail":355,"title":356,"type":357},"{\"arXiv\":\"https://arxiv.org/pdf/2105.03260\"}","[\"Liu Liu*\",\"Han Xue*\",\"Wenqiang Xu\",\"Haoyuan Fu\",\"Cewu Lu (*Equal contribution)\"]","{\"acronym\":\"TIP\",\"year\":2022,\"name\":\"IEEE Transactions on Image Processing.\"}","articulation_real.png","Toward Real-World Category-Level Articulation Pose Estimation","journal",[],{"type":18,"tag":256,"props":360,"children":366},{":artifactLinks":361,":authors":362,":venue":363,"thumbnail":364,"title":365,"type":263},"{\"Proceeding\":\"https://www.bmvc2021-virtualconference.com/assets/papers/0544.pdf\",\"arXiv\":\"https://arxiv.org/pdf/2112.07334.pdf\",\"Code\":\"https://github.com/xiaoxiaoxh/OMAD\"}","[\"Han Xue*\",\"Liu Liu*\",\"Wenqiang Xu\",\"Haoyuan Fu\",\"Cewu Lu (*Equal contribution)\"]","{\"acronym\":\"BMVC\",\"year\":2021,\"name\":\"The 32nd British Machine Vision Conference.\"}","omad.png","OMAD: Object Model with Articulated Deformations for Pose Estimation and Retrieval",[],{"type":18,"tag":256,"props":368,"children":374},{":artifactLinks":369,":authors":370,":venue":371,"thumbnail":372,"title":373,"type":263},"{\"Proceeding\":\"https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123660222.pdf\",\"arXiv\":\"https://arxiv.org/pdf/1912.11473.pdf\",\"Code\":\"https://github.com/justimyhxu/Dense-RepPoints\"}","[\"Ze Yang*\",\"Yinghao Xu*\",\"Han Xue*\",\"Zheng Zhang\",\"Raquel Urtasun\",\"Liwei Wang\",\"Stephen Lin\",\"Han Hu (*Equal contribution)\"]","{\"acronym\":\"ECCV\",\"year\":2020,\"name\":\"The European Conference on Computer Vision.\"}","dense_reppoints.jpg","Dense RepPoints: Representing Visual Objects with Dense Point Sets",[],{"type":18,"tag":256,"props":376,"children":383},{":artifactLinks":377,":authors":378,":venue":379,"thumbnail":380,"title":381,"type":263,":hideBottomBorder":382},"{\"Proceeding\":\"http://openaccess.thecvf.com/content_cvpr_2018/papers/Chen_LiDAR-Video_Driving_Dataset_CVPR_2018_paper.pdf\",\"Code\":\"https://github.com/driving-behavior/DBNet\",\"Website\":\"http://www.dbehavior.net/\"}","[\"Yiping Chen*\",\"Jingkang Wang*\",\"Jonathan Li\",\"Cewu Lu\",\"Zhipeng Luo\",\"Han Xue\",\"Cheng Wang (*Equal contribution)\"]","{\"acronym\":\"CVPR\",\"year\":2018,\"name\":\"Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.\"}","dbnet.jpg","Lidar-video driving dataset: Learning driving policies effectively","true",[],{"type":18,"tag":31,"props":385,"children":386},{},[387],{"type":18,"tag":37,"props":388,"children":390},{"href":389},"/publication/",[391],{"type":28,"value":392},"Full publication list >>>",{"type":18,"tag":23,"props":394,"children":396},{"id":395},"talks",[397],{"type":28,"value":398},"✨ Talks",{"type":18,"tag":400,"props":401,"children":402},"ul",{},[403,426,447],{"type":18,"tag":404,"props":405,"children":406},"li",{},[407,409,416,418,425],{"type":28,"value":408},"[Apr. 2025] Invited talk @ ",{"type":18,"tag":37,"props":410,"children":413},{"href":411,"rel":412},"https://www.techbeat.net/",[41],[414],{"type":28,"value":415},"TechBeat",{"type":28,"value":417}," (将门创投) on \"Robotic Imitation Learning with Vision-Tactile/Force Sensing\". The link of the recorded video is ",{"type":18,"tag":37,"props":419,"children":422},{"href":420,"rel":421},"https://www.techbeat.net/talk-info?id=963",[41],[423],{"type":28,"value":424},"here",{"type":28,"value":218},{"type":18,"tag":404,"props":427,"children":428},{},[429,431,438,440,446],{"type":28,"value":430},"[Dec. 2024] Invited talk @ ",{"type":18,"tag":37,"props":432,"children":435},{"href":433,"rel":434},"https://www.roscon.cn/2024/index.html",[41],[436],{"type":28,"value":437},"ROSCon China 2024",{"type":28,"value":439}," workshop on \"Development Trends and Challenges in Embodied AI\". The link of the recorded video is ",{"type":18,"tag":37,"props":441,"children":444},{"href":442,"rel":443},"https://www.bilibili.com/video/BV1Z3cteAEnD/?spm_id_from=333.337.search-card.all.click&vd_source=8e062051896958b92b4759e0f4753657",[41],[445],{"type":28,"value":424},{"type":28,"value":218},{"type":18,"tag":404,"props":448,"children":449},{},[450,452,458],{"type":28,"value":451},"[Oct. 2024] Invited talk @ ",{"type":18,"tag":37,"props":453,"children":455},{"href":112,"rel":454},[41],[456],{"type":28,"value":457},"TEA lab",{"type":28,"value":459}," in Tsinghua University, IIIS on \"Efficient Learning for Long-horizon Deformable Object Manipulation\"",{"type":18,"tag":23,"props":461,"children":463},{"id":462},"awards",[464],{"type":28,"value":465},"🏆 Awards",{"type":18,"tag":400,"props":467,"children":468},{},[469,474,479,484,489,494,499],{"type":18,"tag":404,"props":470,"children":471},{},[472],{"type":28,"value":473},"Outstanding Graduates in Shanghai (Top 3%) [上海市优秀毕业生] in 2021.",{"type":18,"tag":404,"props":475,"children":476},{},[477],{"type":28,"value":478},"Rongchang Technology Innovation Scholarship (Top 10 students in SJTU) [荣昶科技创新奖学金] in 2020.",{"type":18,"tag":404,"props":480,"children":481},{},[482],{"type":28,"value":483},"SenseTime Scholarship (Top 21 undergraduates in China) [商汤奖学金] in 2020.",{"type":18,"tag":404,"props":485,"children":486},{},[487],{"type":28,"value":488},"National Scholarship (Top 3 students in CS Department) in 2017, 2018 and 2019 (three consecutive years) [国家奖学金（连续三年）].",{"type":18,"tag":404,"props":490,"children":491},{},[492],{"type":28,"value":493},"Academic Excellence Scholarship (Class A) of SJTU (Top 1% in SJTU) in 2018.",{"type":18,"tag":404,"props":495,"children":496},{},[497],{"type":28,"value":498},"Meritorious Winner Prize of Mathematical Contest in Modeling in 2018.",{"type":18,"tag":404,"props":500,"children":501},{},[502],{"type":28,"value":503},"1st Prize in China Undergraduate Mathematical Contest in Modeling (Shanghai Division) in 2017.",{"type":18,"tag":23,"props":505,"children":507},{"id":506},"find-me",[508],{"type":28,"value":509},"📧 Find Me",{"type":18,"tag":511,"props":512,"children":515},"contact-item",{"icon":513,"url":514},"email","mailto:xiaoxiaoxh@sjtu.edu.cn",[516],{"type":18,"tag":31,"props":517,"children":518},{},[519],{"type":28,"value":520},"Email",{"type":18,"tag":511,"props":522,"children":525},{"icon":523,"url":524},"github","https://github.com/xiaoxiaoxh",[526],{"type":18,"tag":31,"props":527,"children":528},{},[529],{"type":28,"value":530},"GitHub",{"type":18,"tag":511,"props":532,"children":535},{"icon":533,"url":534},"twitter","https://twitter.com/HanXue012",[536],{"type":18,"tag":31,"props":537,"children":538},{},[539],{"type":28,"value":540},"Twitter",{"title":12,"searchDepth":542,"depth":542,"links":543},2,[544,545,546,547,548,549,550],{"id":25,"depth":542,"text":29},{"id":126,"depth":542,"text":129},{"id":145,"depth":542,"text":148},{"id":251,"depth":542,"text":254},{"id":395,"depth":542,"text":398},{"id":462,"depth":542,"text":465},{"id":506,"depth":542,"text":509},"markdown","content:index.md","content","index.md","md","default",["ShallowRef",558],["ShallowReactive",559],{"/":560},[561,562],null,{"_path":563,"_dir":12,"_draft":6,"_partial":6,"_locale":12,"title":564,"description":12,"leadingImage":565,"disableFancyImage":5,"_type":551,"_id":566,"_source":553,"_file":567,"_extension":555},"/news","News","me-news-google.png","content:news.md","news.md",["ShallowRef",569],{},[571,572,573],{"title":13,"_path":11},{"title":564,"_path":563},{"title":574,"_path":575},"Publications","/publication",["Reactive",577],{"content-query-1DxZ1vYQk5":561,"content-query-B6mqoO8PxR":561},1750309680598]</script>
<script>window.__NUXT__={};window.__NUXT__.config={public:{mdc:{components:{prose:true,map:{p:"prose-p",a:"prose-a",blockquote:"prose-blockquote","code-inline":"prose-code-inline",code:"ProseCodeInline",em:"prose-em",h1:"prose-h1",h2:"prose-h2",h3:"prose-h3",h4:"prose-h4",h5:"prose-h5",h6:"prose-h6",hr:"prose-hr",img:"prose-img",ul:"prose-ul",ol:"prose-ol",li:"prose-li",strong:"prose-strong",table:"prose-table",thead:"prose-thead",tbody:"prose-tbody",td:"prose-td",th:"prose-th",tr:"prose-tr"}},headings:{anchorLinks:{h1:false,h2:true,h3:true,h4:true,h5:false,h6:false}}},content:{locales:[],defaultLocale:"",integrity:1750309662582,experimental:{stripQueryParameters:false,advanceQuery:false,clientDB:false},respectPathCase:false,api:{baseURL:"/api/_content"},navigation:{fields:["navTitle","layout"]},tags:{p:"prose-p",a:"prose-a",blockquote:"prose-blockquote","code-inline":"prose-code-inline",code:"ProseCodeInline",em:"prose-em",h1:"prose-h1",h2:"prose-h2",h3:"prose-h3",h4:"prose-h4",h5:"prose-h5",h6:"prose-h6",hr:"prose-hr",img:"prose-img",ul:"prose-ul",ol:"prose-ol",li:"prose-li",strong:"prose-strong",table:"prose-table",thead:"prose-thead",tbody:"prose-tbody",td:"prose-td",th:"prose-th",tr:"prose-tr"},highlight:{theme:"dracula",preload:["bibtex"]},wsUrl:"",documentDriven:{page:true,navigation:true,surround:true,globals:{},layoutFallbacks:["theme"],injectPage:true},host:"",trailingSlash:false,contentHead:true,anchorLinks:{depth:4,exclude:[1]}}},app:{baseURL:"/",buildAssetsDir:"/_nuxt/",cdnURL:""}}</script></body>
</html>